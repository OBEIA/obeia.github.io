{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OBEIA CISC/CMPE 322 / CISC 326 Software Architecture W22 Group 35 Welcome Apollo is an \"open autonomous driving platform\" intended for the development of autonomous cars. Initially announced in 2017, it has since developed in various aspects toward driverless driving, with an emphasis on security and safety as the vehicle drives in more complex situations. Methods such as deep learning have been implemented in its software, improving aspects of its autonomy such as perception; further details may be found on its releases page . The architecture of a software system such as Apollo is an integral aspect of its evolution; the system's development is intricately affected by how the architecture has been defined, and any changes or additions may cause a heavy impact to both. Over the course of our project, OBEIA will be studying Apollo to gain an understanding of the development of its architecture, notably that of 7.0. Our site will record our findings from the architecture's concept recovery to its concrete build, ending with a possible enhancement and how the architecture would be affected.","title":"Home"},{"location":"#obeia","text":"CISC/CMPE 322 / CISC 326 Software Architecture W22 Group 35","title":"OBEIA"},{"location":"#welcome","text":"Apollo is an \"open autonomous driving platform\" intended for the development of autonomous cars. Initially announced in 2017, it has since developed in various aspects toward driverless driving, with an emphasis on security and safety as the vehicle drives in more complex situations. Methods such as deep learning have been implemented in its software, improving aspects of its autonomy such as perception; further details may be found on its releases page . The architecture of a software system such as Apollo is an integral aspect of its evolution; the system's development is intricately affected by how the architecture has been defined, and any changes or additions may cause a heavy impact to both. Over the course of our project, OBEIA will be studying Apollo to gain an understanding of the development of its architecture, notably that of 7.0. Our site will record our findings from the architecture's concept recovery to its concrete build, ending with a possible enhancement and how the architecture would be affected.","title":"Welcome"},{"location":"assignment0/","text":"Apollo Resources General Resources Apollo Website Apollo Auto Blog Apollo Auto YouTube Channel Apollo Platform Twitter Policies Project Governance Policy Project Contribution Guide Development Main Source Code Repository Apollo Auto GitHub Organization Apollo Platform Issue Tracker Basic Documentation Release Details Apollo Platform Component Detail Quick Start Guide Index How-To Guide Index FAQ Index Advanced Documentation Apollo Developer Course Technical Tutorial Index Hardware and Software Component Specifications Technical Code Readings and Algorithm Details Domain Research A functional reference architecture for autonomous driving","title":"Apollo Resources"},{"location":"assignment0/#apollo-resources","text":"","title":"Apollo Resources"},{"location":"assignment0/#general-resources","text":"Apollo Website Apollo Auto Blog Apollo Auto YouTube Channel Apollo Platform Twitter","title":"General Resources"},{"location":"assignment0/#policies","text":"Project Governance Policy Project Contribution Guide","title":"Policies"},{"location":"assignment0/#development","text":"Main Source Code Repository Apollo Auto GitHub Organization Apollo Platform Issue Tracker","title":"Development"},{"location":"assignment0/#basic-documentation","text":"Release Details Apollo Platform Component Detail Quick Start Guide Index How-To Guide Index FAQ Index","title":"Basic Documentation"},{"location":"assignment0/#advanced-documentation","text":"Apollo Developer Course Technical Tutorial Index Hardware and Software Component Specifications Technical Code Readings and Algorithm Details","title":"Advanced Documentation"},{"location":"assignment0/#domain-research","text":"A functional reference architecture for autonomous driving","title":"Domain Research"},{"location":"assignment1/","text":"The Conceptual Architecture of Apollo Click here to access this report as a PDF. (Requires Queen's University login.) Click here to access the accompanying presentation slides. (Requires Queen's University login.) Abstract Apollo is an open-source autonomous driving platform supporting the development of systems for self-driving vehicles. Such a system must carefully develop its architecture to fulfil the requirements of stakeholders such as investors, developers and users. To extract the software system\u2019s conceptual architecture, we considered a reference architecture created by Sagar Behere and Martin T\u00f6rngren, as well as Apollo\u2019s documentation, notably that found on their current version (7.0) and version 5.5 GitHub pages. This documentation reveals an architecture containing various components mapping to the reference architecture. Apollo\u2019s architecture largely relies on a publish-subscribe style that allows for high concurrency and performance, as well as simplified system evolution. Introduction Software System Apollo is an autonomous driving platform specializing in supporting the development of self-driving vehicles. Initially announced in 2017, the project has since developed from being able to follow GPS Waypoints towards fully \u201cdriverless driving;\u201d as of December 2021, Apollo has reached version 7.0. The system is open-source and documented in detail. [GitHub] Apollo\u2019s Open Software Platform needs a complex system to fulfil the requirements of an autonomously driving vehicle. In particular, the system needs to be able to determine its surroundings and situation, predict how these may change, and plan how the vehicle will move accordingly, ultimately determining the vehicle\u2019s trajectory. These functions must perform efficiently and accurately for the system to run as expected in real-life scenarios that vehicles and their drivers experience. This report studies and describes the conceptual architecture used within the system. Derivation Process Deriving the architecture presented involved reading academic papers as well as the Apollo documentation, including that from previous versions, such as 5.5. Sagar Behere and Martin T\u00f6rngren have formed a functional reference architecture for autonomous driving platforms up to level L4 of autonomy [Behere and T\u00f6rngren 138] . As they discuss, this form of architecture is the starting point for architectural design of a system and may aid in other implementations in the field of focus, in this case, self-driving vehicles. Their reference architecture is depicted in Figure 1; it includes a variety of modules and components relating to the functionality of the vehicle. Figure 1: A functional reference architecture for an autonomous driving platform, as provided by Behere and T\u00f6rngren. [ibid., 143] Components relating to the system\u2019s perception include sensors; a \u201csensor fusion\u201d that forms an idea regarding the environment; a localization component relating to the location of the vehicle; a \u201csemantic understanding\u201d component; and a \u201cworld model\u201d component that describes the external world of the vehicle. These components connect, as shown in detail in Figure 1, to perceive and understand the environment that the vehicle is in. [ibid., 139-140] The decision and control component works to understand the vehicle\u2019s various characteristics, including trajectories it can travel (as well as the \u201coptimal\u201d one) and its energy (electricity, gas, hybrid, etc.). By understanding these characteristics, this component may make the appropriate decisions, hence controlling what the system does. [ibid., 140-141] The vehicle platform itself refers to the internal system, including the execution of trajectories, managing the energy that is noted in the energy sub-component of decision and control, and managing the safety and control of the vehicle, including regularly considering the state of the system via the diagnostics and faults management systems. [ibid., 141] Requirements We initially identified three main categories of stakeholders and their high-level needs based on their type of interaction with the system. Starting at the production end is any stakeholder involved with the design, manufacturing, and selling of the system; this might include engineers, developers, producers, and investors. Their needs are focused on modularity and adaptability; reducing complexity and use of existing resources can lead to faster prototyping and lower costs. The second category are the users who purchase or otherwise own and depend primarily on the functionality of the system. Their needs are convenience (usability, affordability, etc.) and effectiveness. The remaining group of stakeholders is the technical support, whose needs involve diagnostics and modifications. Apollo is a complex platform that has been built over time based on specific driving cases. [GitHub] Understanding the requirements of such a system is integral to its development, particularly as vehicles are an aspect of urban life where safety is essential. For this, any driver must be aware of their surroundings and react accordingly. Thus an autonomous system that imitates a driving experience requires excellent performance\u2014it must be able to react in short periods of time while at the same time driving as accurately as a user (and any person on the road) expects. Being on the road brings a variety of complex situations that must be considered for the system while maintaining good performance. Apollo is a system that connects to the cloud for security purposes, as well as calibration [Baidu] ; the system\u2019s security is important to the safety of those on the road. Apollo offers various products relating to security for its system. IDPS takes note of errors as soon as possible and reports them to the cloud, also preventing them from affecting the entire system. Secure IVI considers applications and prevents unauthorized access by suspicious apps. [Baidu] Authorization is integral to the system, protecting from any potential attackers; encryption may also deter them. Thus, a system such as Apollo must take security seriously. Any autonomous system needs to be reliable, as a user would expect the system to be able to mostly drive on its own and make decisions as appropriate in short periods of time. Such a system must be continuously available. Security systems notice errors within the system and react accordingly, so the system should be as available as possible to ensure errors are noticed; the system being unavailable may also negatively impact safety. Apollo also highlights the importance of its use by other developers interested in the platform, including the implementation of an online development platform dedicated to this development. [GitHub] Modifiability, then, would be an important non-functional requirement for the system to ease these developers in their process. The development process of Apollo from 1.0 to 7.0 has been documented in detail, with summaries on their GitHub release page; a variety of requirements for the system may be extracted from the release summaries alone. These functional requirements include but are not limited to: (1) driving by following GPS signals; (2) cruising, not only in lanes but also in urban roads and on highways; (3) avoiding collisions with other vehicles, objects, pedestrians, etc.; (4) changing lanes as appropriate; (5) stopping at traffic lights; (6) safely turning at intersections; and (7) parking with the appropriate method. Conceptual Architecture Overview Figure 2: Apollo 3.5 software architecture core modules interaction diagram, from the project documentation on GitHub. [GitHub] Figure 2 represents the software architecture of Apollo as of version 3.5. As a top-level view of the architecture, it does not describe the system as closely as the functional reference architecture created by Behere and T\u00f6rngren; however, both architectures feature similar key components, including perception, localization, and control. The planning component in the Apollo architecture may also coincide with the decision and control component of the reference architecture. Figure 3: Description of various aspects of the Apollo 7.0 platform, as highlighted in the project documentation on GitHub. [GitHub] Figure 3 displays key components in the Apollo platforms; the Open Software Platform section of the figure includes some similar components as in the architecture but includes a V2X adapter and Apollo Cyber RT (described below), all running on a real-time operating system (RTOS), as well as a map engine relating to the HD map within the architecture (that is instead shown within the Cloud Service Platform). The Apollo software architecture documentation only extends up to version 5.5, but while it has not been updated for releases 6.0 and 7.0, those have primarily added new deep learning models and developer frontends and have not significantly changed the overall architecture. Studying Apollo\u2019s documentation reveals that the software platform consists of thirteen major subsystems: twelve providing autonomous vehicle functionality, and one providing a communication and runtime framework for the operation of the others. This central runtime is known as Apollo Cyber RT and is described in further detail below. Figure 4: The dependency relations of Apollo\u2019s software modules, derived from descriptions in the project documentation. Figure 5: The communication flow between the core Apollo modules. Using Apollo project documentation, the names and functionality of the major modules of the software platform were identified and their interactions diagrammed as dependency relations in Figure 4. These interactions end up being quite complex. However, the Cyber RT framework provides the communication facilities for the modules to interact, primarily in a publish-subscribe pattern. This allows the system overall to remain largely decoupled, as shown in Figure 5. Subsystems Apollo contains thirteen major modules or subsystems within it: Cyber RT, Perception, Prediction, Planning, Storytelling, Routing, HD Map, Monitor, Dreamview, Guardian, Localization, Control, and CanBus. [GitHub] The following subsections describe these modules and explore how they relate to Behere and T\u00f6rngren\u2019s reference architecture in Figure 1. Cyber RT The central subsystem of Apollo\u2019s architecture is a custom runtime framework known as Cyber RT . This runtime system is responsible for loading and launching the other major components and providing a mechanism for them to communicate with one another. The developers of Apollo describe this component as high concurrency and throughput that allows for high performance; it is specialized for autonomous driving. [GitHub] Using channels (or topics) of Cyber RT, modules communicate in a publish-subscribe manner, allowing for flexibility and decoupling of modules; they may also communicate in a client/server method through this component. [GitHub] Perception The Perception subsystem is a low-level component which takes input directly from physical sensors mounted on a vehicle. These sensors include two forward-facing cameras, four LiDAR sensors with each facing a different direction as well as forward- and rear-facing radar. Stereo images provided by the cameras and LiDAR data are fed to a deep learning model which labels objects in the field of view. Objects are also tracked through each of the sensor systems (camera, radar, LiDAR) and the results amalgamated by the \u201csensor fusion\u201d module. Ultimately this subsystem outputs decisions on the state of nearby traffic lights and a list of objects which are labelled with their type, distance away and velocity. [GitHub] The perception subsystem of Apollo overlaps with some functions of the External Sensing, Sensor Fusion, Semantic Understanding and External World Model subsystems of the reference architecture. Prediction The Prediction subsystem predicts the future movements of objects identified by the perception module. This subsystem takes input from the perception component as well as the localization and planning subsystems. Internal architecture of this system is structured sequentially. The \u201cscenario\u201d submodule characterizes the situation as either cruise, for simple driving in lane, or junction, for driving in an intersection. Then, obstacles are given a priority label which is either \u201ccaution\u201d, \u201cignore\u201d, or \u201cnormal\u201d. The \"evaluator\u201d submodule independently predicts a path and a speed for each obstacle and marks the path with a probability. Finally, a \u201cpredictor\u201d submodule produces an expected trajectory for each obstacle. [GitHub] The prediction subsystem of Apollo performs tasks that are under the Semantic Understanding and External World Model subsystems of the reference architecture. Planning The Planning subsystem is a high-level component that aims to plan the exact route of the vehicle. This subsystem receives data from the Prediction and HD map components to plan short term goals, such as waiting at a traffic light, avoiding a collision, or staying in a lane. Then the planning module receives route data from the Routing module and plans the future trajectory of the vehicle through high-level maneuvers such as executing a three-point turn. In the case where the vehicle is unable to follow the route prescribed by the Routing module, the Planning module may request a new routing computation. [GitHub] The planning module of Apollo is roughly equivalent to the Trajectory system within the control module of the reference architecture. Storytelling The Storytelling subsystem is a high-level scenario manager intended to coordinate inter-module actions. Complex driving scenarios require intensive communication between modules. To avoid a sequential architecture in these situations, the storytelling module creates \u201cstories\u201d; complex scenarios that trigger many other modules. These stories are published and can be subscribed to by any other module. [GitHub] The Storytelling subsystem is specific to the implementation of Apollo and does not have a mapping to the reference architecture. Routing The Routing subsystem generates navigation paths given a target start and end point, using the topology of the terrain. Typically, the end point is the destination of the passenger, and the start point is the current location of the vehicle. This subsystem does high-level navigation using map data and could be compared to a GPS installed in most cars today. A routing map is outputted and used for the lower-level navigation done by Planning. [GitHub] The Routing component of Apollo could be part of the trajectory component of the reference architecture. However, it is unclear whether the reference architecture treats navigation as a Trajectory task, a Localization task or a cloud server task. HD Map The HD Map functions as a query engine for the other modules to provide on demand, high granularity information about the roads. It retrieves map data from the cloud upon request and caches map data for repeated reuse. The information from the HD Map is queried by the routing module to plan high level routes. [GitHub] Apollo\u2019s HD Map has both an onboard client component as well as an offboard server component. There are two possible interpretations of the reference architecture documentation as it pertains to navigation. One possibility is that all map data is stored onboard in the Localization module. Another is that map and routing functions are performed off the vehicle platform. The maps are then remotely sent to the vehicle to contribute to the vehicle\u2019s External World Model. Monitor The Monitor module provides status checks of both hardware and software components of the system. This subsystem surveils all the modules of the vehicle, as well as hardware to ensure they are working as intended. This data is passed to the Dreamview for the passenger to easily view the status of the system. [GitHub] The Monitor component of Apollo has a similar function to Platform Fault Management in the reference architecture. Dreamview Dreamview , Apollo\u2019s HMI module, provides a UI in the form of a web application that allows developers or vehicle passengers to visualize the data produced by other subsystems. Given the inputs of the other modules, Dreamview produces a three-dimensional representation of the vehicle including the current location and planned path. Additionally, using data from the Monitor module, Dreamview displays the status of the components and hardware of the vehicle. [GitHub] Apollo\u2019s Dreamview visualization interface is an example of a service that is performed offboard in the reference architecture, in this case both tele-operation and remote monitoring. Guardian The Guardian module serves as an \u201caction center\u201d that will only react in case of module failure. Using reports sent by the Monitor, the Guardian may do one of two things. If all modules are working as expected, the Guardian allows the process to continue normally. If the Monitor detects failure of some form, the Guardian works to handle the failure by preventing controls from reaching the CanBus, then stopping the vehicle. The Guardian manages two main types of shutdowns. If the sensors are operating normally and do not detect any obstacles the vehicle will enter a controlled slow stop by applying light breaking. In the second scenario, if the sensors are not operating normally, the Guardian applies heavy breaking to bring the car to an immediate stop. [GitHub] Apollo\u2019s Guardian module works with the Monitor module to produce the functions of Platform Management in the reference architecture. Localization The Localization component is a low-level module that provides localization services to other components. Depending on the hardware available in the car, this module can use a combination of GPS, an inertial measurement unit, and LiDAR. The localization component outputs an estimate of the vehicle's location. [GitHub] Apollo\u2019s Localization module is equivalent to the Localization module in the reference architecture. Control The Control component generates control commands for the vehicle to create a \u201ccomfortable driving experience.\u201d Using the localization of the vehicle, the car status, and the trajectory created by the Planning module, commands are created by various algorithms depending on the scenario. Commands include those for the steering, brakes, and throttle, to be used by the chassis. These commands are passed to the CanBus to control the vehicle hardware. [GitHub] Apollo\u2019s Control module is comparable to the Control module in the reference architecture. However, the reference architecture considers several decision-making functions to be within the Control subsystem whereas Apollo\u2019s Control module is separate from its Planning and Guardian, for example. CanBus CanBus works closely with the Control module, acting as the interface between the software system and the physical vehicle chassis. In one direction, the module uses a suite of sensors specific to the vehicle model to report the status of the car to Control. In the other direction, it executes the actions required to actualize the commands sent from Control, such as changing direction, engaging brakes, and accelerating. [GitHub] The CanBus module onboard the Apollo software system is one implementation of the Vehicle Platform Abstraction component of the reference architecture. Concurrency The Cyber RT framework that underlies the other modules of the software platform provides several mechanisms for concurrency. At a high level, it implements a \u201ctask\u201d abstraction to describe asynchronous computing operations. Beyond this, Cyber RT provides different resource scheduling algorithms that developers can choose from to better suit specific scenarios, as well as a coroutine implementation called \u201cCRoutine\u201d that optimizes system resource and thread utilization. [GitHub] Architecture Styles The primary architectural style present in the Apollo software platform is publish-subscribe, which allows the various subsystems to interact in a well-defined and loosely coupled manner. As discussed previously, the Apollo Cyber RT system acts as a message broker in this architecture. Cyber provides an implementation of \u201cchannels\u201d as a mechanism of data communication between the other modules, which can act as either \u201creaders\u201d or \u201cwriters\u201d in respect to a given channel. [GitHub] Acting as a writer, a module publishes messages to a channel, consisting of structured data such as commands, events, or sensor data. When acting as a reader, a module has defined interfaces that handle processing and reacting to messages on subscribed channels according to registered function callbacks. [GitHub] There does not seem to be any limit to how many channels a module can act as a reader or writer on, but each writer interface defines a unique channel to enforce isolation by message \u201ctopic\u201d. There are many benefits to the publish-subscribe model in a system as complex as Apollo. By relying on broadcast events, modules can send out commands or data to other parts of the system without having to lose process control or wait for responses. This is crucial in the domain of autonomous driving as continuous operation of all subsystems is critical for the continuing operation and safety of the vehicle and its occupants. From a development standpoint, the architecture also allows for the various subsystem modules to be independent and isolated, only interacting by certain strict mechanisms and interfaces, and keeping them loosely coupled. It also simplifies future evolution of the system, since the strict interfaces and loose coupling make it easier for modules to be split, replaced, or even removed, and for new modules to be added. However, publish-subscribe is not the only communication mechanism present in the platform, and while it is prevalent enough to define the overall architecture there are certain components that interact according to other patterns. In addition to the publish-subscribe facilities, Cyber RT also provides interfaces for client-server-style interaction, for scenarios requiring two-way request-response communication. [GitHub] One case where this is used seems to be in making ad hoc queries to the HD Map module. Finally, it is worth noting that by using these mechanisms, the Control and CanBus subsystems implement a process control pattern. In this sense, the Control module acts as the controller, creating execution plans for car actions based on requirements and data from the other modules, while the CanBus acts as the process, interfacing with the actual physical vehicle to actualize the commands from Control as well as providing it with feedback from chassis sensors. Use Cases Figure UC0: Sequence diagram of the \u2018loop\u2019 that the Apollo system goes through as it creates the optimal path for the vehicle to go. It is described in the text. Figure UC0 displays how the system logic works in a loop of sorts, in that this process continues to be performed while the vehicle is driven, and the appropriate modules are working. The Localization module must first estimate the location of the vehicle and publish it to Cyber RT, which brokers the data to all subscribed modules. Routing and Storytelling both use the localization data, as well as queried map data from HD Map, to generate a route and a story, respectively. These are published to and brokered by Cyber RT. After receiving data from the sensors, the Perception module then determines obstacles, lanes, and traffic light status (if applicable), which is again published to and brokered by Cyber RT. The Prediction module uses this Perception data, as well as Localization, Routing, and the previous trajectory of Planning, to predict obstacle trajectories and prioritize them. These are published to Cyber RT, then sent to the Planning module; given Localization, Perception, Prediction, Routing, and Storytelling, as well as queried map data, the optimal trajectory is created by Planning. It is published to Cyber RT, then brokered to Prediction and Control. The Control module then generates the appropriate control commands, which are published. If the system is in a good state, then the CanBus retrieves these controls, sending them to the hardware, and publishes chassis data. While these processes are running, the HMI retrieves data using Cyber RT\u2019s channels, displaying them to the user or driver. The Monitor may also retrieve these data, processing them and publishing a report that details the state of the modules; Cyber RT then sends the report to both the HMI and Guardian. The HMI displays the report\u2019s results, while the Guardian ensures that there are no issues. If there are any failures, however, then the Guardian will enact its procedure to handle it as described in Subsystems . Use case 1: Lane following The first use case is the default lane following. In this use case, the vehicle is to stay within its lane and follow another car at a safe distance. First, hardware sensors described in Subsystems feed data to the perception module. The perception module then identifies lane lines as well as the other car, but does not identify any traffic lights in this case. Sensor fusion takes the labelled objects and sensor data to assign the car ahead with a distance and velocity. Lane lines are marked with their distance away. This information is published to Cyber RT and picked up by the prediction module. By identifying that there are currently no traffic lights ahead, the prediction module characterizes the scenario as \u201ccruise\u201d. The leading car is assigned priority \u201ccaution\u201d as it may affect the ego car\u2019s trajectory. Eventually, a trajectory for the leading car is predicted and, in this case, that trajectory is continuing in the lane and either slowing down or speeding up. This trajectory is published to Cyber RT and picked up by Planning. Planning uses the predicted trajectory of the leading car to produce a \u201ccollision-free and comfortable\u201d trajectory for the ego car. In this use case, the trajectory would be to direct the car within the lane and at a speed similar to the leading car. This trajectory is published to Cyber RT and picked up by the control module. The control module uses the planned trajectory along with localization information and car status coming from the CanBus to produce control signals for steering, brakes and throttle. In this case, it would be expected that the steering signal would only change the position of the wheels to follow the lane. Throttle and brake control signals should be mostly neutral as well unless the car ahead is stopping or accelerating quickly. Figure UC1: Sequence diagram for the lane following use case, focusing on the system\u2019s process from Perception to CanBus. Use case 2: Unprotected left turn The second use case to be considered is the \u201cUnprotected Left\u201d scenario described in the details of the Planning module of Apollo 5.5 [GitHub] ; it is one scenario relating to a traffic light that remains within the Planning module [GitHub] . In this use case, the vehicle is to turn left through an intersection with a traffic light to continue to its destination; the term \u201cunprotected\u201d refers to how there is no distinct left/right turn light; the vehicle must yield to oncoming traffic. Specifics of what the vehicle should do are detailed in the README of 5.5\u2019s Planning module. Figure UC2: Sequence diagram of the Planning module\u2019s determination of the optimal trajectory for the given use case of \u201cunprotected left turn.\u201d Figure UC2 highlights the process that the Planning module runs to determine the optimal trajectory for the vehicle. The various inputs that were brokered by Cyber RT are stored; then, the \u201cScenario Decider\u201d determines the scenario that is to be handled: Traffic Light, Unprotected Left. This is done by noting the traffic light status that was determined by Perception. Using this scenario as well as the inputs (particularly route and map), the module plans a path for the vehicle; this is then used by the speed planner (in addition to the input) to determine an optimal speed. If the vehicle needs to stop, then it should slow or stop; otherwise, it should first \u201ccreep\u201d forward to determine if no \u201cobstacles\u201d are present. Once in the intersection, it must yield to oncoming vehicles by slowing down, or otherwise continue driving safely at the appropriate speed for the intersection. This is done by taking note both of obstacles noted by Perception as well as the corresponding predicted trajectories and priorities given by Prediction. Using the path and speed, a trajectory is made and finally sent for other modules such as Control to access. Lessons Learned This report was a complex undertaking and as such we learned a lot in the process of completing it. As it was our group\u2019s first major project together, we learned in the process of it each other\u2019s strengths and weaknesses and styles of working, which will hopefully make planning for future deliverables easier. In respect to the topic itself, we realized just how revealing quality documentation can be, and how much it can reveal about a system on close reading, though its accuracy remains to be seen. To that end, it took us some time to realize how crucial documentation for older versions of Apollo would be to our understanding of the platform, and initially ignoring anything that was not marked for the latest version slowed down initial work significantly. Glossary L4 Autonomy: SAE International has created a standard, \u201cJ3016 Levels of Automated Driving.\u201d These levels range from Level 0 (no automation) to Level 5 (full autonomy). Level 4 (L4) is described as highly automated with features able to drive the vehicle in limited conditions, compared to Level 5 which may drive in all conditions. [SAE] HMI: Human Machine Interface IDPS: Intrusion Detection and Prevention System [Baidu] IVI: In-Vehicle Infotainment LiDAR: Light Detection and Ranging References Apollo Auto. \u201cRobotaxi: Autonomous Driving Solution.\u201d Baidu (2020). Retrieved from https://apollo.auto/robotaxi/index.html. Apollo Auto. \u201cApollo Cyber Security.\u201d Baidu (2020). Retrieved from https://apollo.auto/platform/security.html. ApolloAuto. \u201cApolloAuto/apollo: An open autonomous driving platform.\u201d GitHub. Last accessed February 18, 2022. Retrieved from https://github.com/ApolloAuto/apollo. ApolloAuto. \u201cPlanning README at 5.5.0.\u201d GitHub (2020). Retrieved from https://github.com/ApolloAuto/apollo/blob/r5.5.0/modules/planning/README.md. Behere, Sagar, and Martin T\u00f6rngren. \u201cA functional reference architecture for autonomous driving.\u201d KTH The Royal Institute of Technology, Brinellv\u00e4gen 83, Stockholm SE-10044, Sweden (2015): 143. Retrieved from https://www.sciencedirect.com/science/article/abs/pii/S0950584915002177. Shuttleworth, Jennifer. \u201cSAE Standards News: J3016 automated-driving graphic update.\u201d SAE International (January 7, 2019). Retrieved from https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic.","title":"Conceptual Architecture"},{"location":"assignment1/#the-conceptual-architecture-of-apollo","text":"Click here to access this report as a PDF. (Requires Queen's University login.) Click here to access the accompanying presentation slides. (Requires Queen's University login.)","title":"The Conceptual Architecture of Apollo"},{"location":"assignment1/#abstract","text":"Apollo is an open-source autonomous driving platform supporting the development of systems for self-driving vehicles. Such a system must carefully develop its architecture to fulfil the requirements of stakeholders such as investors, developers and users. To extract the software system\u2019s conceptual architecture, we considered a reference architecture created by Sagar Behere and Martin T\u00f6rngren, as well as Apollo\u2019s documentation, notably that found on their current version (7.0) and version 5.5 GitHub pages. This documentation reveals an architecture containing various components mapping to the reference architecture. Apollo\u2019s architecture largely relies on a publish-subscribe style that allows for high concurrency and performance, as well as simplified system evolution.","title":"Abstract"},{"location":"assignment1/#introduction","text":"","title":"Introduction"},{"location":"assignment1/#software-system","text":"Apollo is an autonomous driving platform specializing in supporting the development of self-driving vehicles. Initially announced in 2017, the project has since developed from being able to follow GPS Waypoints towards fully \u201cdriverless driving;\u201d as of December 2021, Apollo has reached version 7.0. The system is open-source and documented in detail. [GitHub] Apollo\u2019s Open Software Platform needs a complex system to fulfil the requirements of an autonomously driving vehicle. In particular, the system needs to be able to determine its surroundings and situation, predict how these may change, and plan how the vehicle will move accordingly, ultimately determining the vehicle\u2019s trajectory. These functions must perform efficiently and accurately for the system to run as expected in real-life scenarios that vehicles and their drivers experience. This report studies and describes the conceptual architecture used within the system.","title":"Software System"},{"location":"assignment1/#derivation-process","text":"Deriving the architecture presented involved reading academic papers as well as the Apollo documentation, including that from previous versions, such as 5.5. Sagar Behere and Martin T\u00f6rngren have formed a functional reference architecture for autonomous driving platforms up to level L4 of autonomy [Behere and T\u00f6rngren 138] . As they discuss, this form of architecture is the starting point for architectural design of a system and may aid in other implementations in the field of focus, in this case, self-driving vehicles. Their reference architecture is depicted in Figure 1; it includes a variety of modules and components relating to the functionality of the vehicle. Figure 1: A functional reference architecture for an autonomous driving platform, as provided by Behere and T\u00f6rngren. [ibid., 143] Components relating to the system\u2019s perception include sensors; a \u201csensor fusion\u201d that forms an idea regarding the environment; a localization component relating to the location of the vehicle; a \u201csemantic understanding\u201d component; and a \u201cworld model\u201d component that describes the external world of the vehicle. These components connect, as shown in detail in Figure 1, to perceive and understand the environment that the vehicle is in. [ibid., 139-140] The decision and control component works to understand the vehicle\u2019s various characteristics, including trajectories it can travel (as well as the \u201coptimal\u201d one) and its energy (electricity, gas, hybrid, etc.). By understanding these characteristics, this component may make the appropriate decisions, hence controlling what the system does. [ibid., 140-141] The vehicle platform itself refers to the internal system, including the execution of trajectories, managing the energy that is noted in the energy sub-component of decision and control, and managing the safety and control of the vehicle, including regularly considering the state of the system via the diagnostics and faults management systems. [ibid., 141]","title":"Derivation Process"},{"location":"assignment1/#requirements","text":"We initially identified three main categories of stakeholders and their high-level needs based on their type of interaction with the system. Starting at the production end is any stakeholder involved with the design, manufacturing, and selling of the system; this might include engineers, developers, producers, and investors. Their needs are focused on modularity and adaptability; reducing complexity and use of existing resources can lead to faster prototyping and lower costs. The second category are the users who purchase or otherwise own and depend primarily on the functionality of the system. Their needs are convenience (usability, affordability, etc.) and effectiveness. The remaining group of stakeholders is the technical support, whose needs involve diagnostics and modifications. Apollo is a complex platform that has been built over time based on specific driving cases. [GitHub] Understanding the requirements of such a system is integral to its development, particularly as vehicles are an aspect of urban life where safety is essential. For this, any driver must be aware of their surroundings and react accordingly. Thus an autonomous system that imitates a driving experience requires excellent performance\u2014it must be able to react in short periods of time while at the same time driving as accurately as a user (and any person on the road) expects. Being on the road brings a variety of complex situations that must be considered for the system while maintaining good performance. Apollo is a system that connects to the cloud for security purposes, as well as calibration [Baidu] ; the system\u2019s security is important to the safety of those on the road. Apollo offers various products relating to security for its system. IDPS takes note of errors as soon as possible and reports them to the cloud, also preventing them from affecting the entire system. Secure IVI considers applications and prevents unauthorized access by suspicious apps. [Baidu] Authorization is integral to the system, protecting from any potential attackers; encryption may also deter them. Thus, a system such as Apollo must take security seriously. Any autonomous system needs to be reliable, as a user would expect the system to be able to mostly drive on its own and make decisions as appropriate in short periods of time. Such a system must be continuously available. Security systems notice errors within the system and react accordingly, so the system should be as available as possible to ensure errors are noticed; the system being unavailable may also negatively impact safety. Apollo also highlights the importance of its use by other developers interested in the platform, including the implementation of an online development platform dedicated to this development. [GitHub] Modifiability, then, would be an important non-functional requirement for the system to ease these developers in their process. The development process of Apollo from 1.0 to 7.0 has been documented in detail, with summaries on their GitHub release page; a variety of requirements for the system may be extracted from the release summaries alone. These functional requirements include but are not limited to: (1) driving by following GPS signals; (2) cruising, not only in lanes but also in urban roads and on highways; (3) avoiding collisions with other vehicles, objects, pedestrians, etc.; (4) changing lanes as appropriate; (5) stopping at traffic lights; (6) safely turning at intersections; and (7) parking with the appropriate method.","title":"Requirements"},{"location":"assignment1/#conceptual-architecture","text":"","title":"Conceptual Architecture"},{"location":"assignment1/#overview","text":"Figure 2: Apollo 3.5 software architecture core modules interaction diagram, from the project documentation on GitHub. [GitHub] Figure 2 represents the software architecture of Apollo as of version 3.5. As a top-level view of the architecture, it does not describe the system as closely as the functional reference architecture created by Behere and T\u00f6rngren; however, both architectures feature similar key components, including perception, localization, and control. The planning component in the Apollo architecture may also coincide with the decision and control component of the reference architecture. Figure 3: Description of various aspects of the Apollo 7.0 platform, as highlighted in the project documentation on GitHub. [GitHub] Figure 3 displays key components in the Apollo platforms; the Open Software Platform section of the figure includes some similar components as in the architecture but includes a V2X adapter and Apollo Cyber RT (described below), all running on a real-time operating system (RTOS), as well as a map engine relating to the HD map within the architecture (that is instead shown within the Cloud Service Platform). The Apollo software architecture documentation only extends up to version 5.5, but while it has not been updated for releases 6.0 and 7.0, those have primarily added new deep learning models and developer frontends and have not significantly changed the overall architecture. Studying Apollo\u2019s documentation reveals that the software platform consists of thirteen major subsystems: twelve providing autonomous vehicle functionality, and one providing a communication and runtime framework for the operation of the others. This central runtime is known as Apollo Cyber RT and is described in further detail below. Figure 4: The dependency relations of Apollo\u2019s software modules, derived from descriptions in the project documentation. Figure 5: The communication flow between the core Apollo modules. Using Apollo project documentation, the names and functionality of the major modules of the software platform were identified and their interactions diagrammed as dependency relations in Figure 4. These interactions end up being quite complex. However, the Cyber RT framework provides the communication facilities for the modules to interact, primarily in a publish-subscribe pattern. This allows the system overall to remain largely decoupled, as shown in Figure 5.","title":"Overview"},{"location":"assignment1/#subsystems","text":"Apollo contains thirteen major modules or subsystems within it: Cyber RT, Perception, Prediction, Planning, Storytelling, Routing, HD Map, Monitor, Dreamview, Guardian, Localization, Control, and CanBus. [GitHub] The following subsections describe these modules and explore how they relate to Behere and T\u00f6rngren\u2019s reference architecture in Figure 1.","title":"Subsystems"},{"location":"assignment1/#cyber-rt","text":"The central subsystem of Apollo\u2019s architecture is a custom runtime framework known as Cyber RT . This runtime system is responsible for loading and launching the other major components and providing a mechanism for them to communicate with one another. The developers of Apollo describe this component as high concurrency and throughput that allows for high performance; it is specialized for autonomous driving. [GitHub] Using channels (or topics) of Cyber RT, modules communicate in a publish-subscribe manner, allowing for flexibility and decoupling of modules; they may also communicate in a client/server method through this component. [GitHub]","title":"Cyber RT"},{"location":"assignment1/#perception","text":"The Perception subsystem is a low-level component which takes input directly from physical sensors mounted on a vehicle. These sensors include two forward-facing cameras, four LiDAR sensors with each facing a different direction as well as forward- and rear-facing radar. Stereo images provided by the cameras and LiDAR data are fed to a deep learning model which labels objects in the field of view. Objects are also tracked through each of the sensor systems (camera, radar, LiDAR) and the results amalgamated by the \u201csensor fusion\u201d module. Ultimately this subsystem outputs decisions on the state of nearby traffic lights and a list of objects which are labelled with their type, distance away and velocity. [GitHub] The perception subsystem of Apollo overlaps with some functions of the External Sensing, Sensor Fusion, Semantic Understanding and External World Model subsystems of the reference architecture.","title":"Perception"},{"location":"assignment1/#prediction","text":"The Prediction subsystem predicts the future movements of objects identified by the perception module. This subsystem takes input from the perception component as well as the localization and planning subsystems. Internal architecture of this system is structured sequentially. The \u201cscenario\u201d submodule characterizes the situation as either cruise, for simple driving in lane, or junction, for driving in an intersection. Then, obstacles are given a priority label which is either \u201ccaution\u201d, \u201cignore\u201d, or \u201cnormal\u201d. The \"evaluator\u201d submodule independently predicts a path and a speed for each obstacle and marks the path with a probability. Finally, a \u201cpredictor\u201d submodule produces an expected trajectory for each obstacle. [GitHub] The prediction subsystem of Apollo performs tasks that are under the Semantic Understanding and External World Model subsystems of the reference architecture.","title":"Prediction"},{"location":"assignment1/#planning","text":"The Planning subsystem is a high-level component that aims to plan the exact route of the vehicle. This subsystem receives data from the Prediction and HD map components to plan short term goals, such as waiting at a traffic light, avoiding a collision, or staying in a lane. Then the planning module receives route data from the Routing module and plans the future trajectory of the vehicle through high-level maneuvers such as executing a three-point turn. In the case where the vehicle is unable to follow the route prescribed by the Routing module, the Planning module may request a new routing computation. [GitHub] The planning module of Apollo is roughly equivalent to the Trajectory system within the control module of the reference architecture.","title":"Planning"},{"location":"assignment1/#storytelling","text":"The Storytelling subsystem is a high-level scenario manager intended to coordinate inter-module actions. Complex driving scenarios require intensive communication between modules. To avoid a sequential architecture in these situations, the storytelling module creates \u201cstories\u201d; complex scenarios that trigger many other modules. These stories are published and can be subscribed to by any other module. [GitHub] The Storytelling subsystem is specific to the implementation of Apollo and does not have a mapping to the reference architecture.","title":"Storytelling"},{"location":"assignment1/#routing","text":"The Routing subsystem generates navigation paths given a target start and end point, using the topology of the terrain. Typically, the end point is the destination of the passenger, and the start point is the current location of the vehicle. This subsystem does high-level navigation using map data and could be compared to a GPS installed in most cars today. A routing map is outputted and used for the lower-level navigation done by Planning. [GitHub] The Routing component of Apollo could be part of the trajectory component of the reference architecture. However, it is unclear whether the reference architecture treats navigation as a Trajectory task, a Localization task or a cloud server task.","title":"Routing"},{"location":"assignment1/#hd-map","text":"The HD Map functions as a query engine for the other modules to provide on demand, high granularity information about the roads. It retrieves map data from the cloud upon request and caches map data for repeated reuse. The information from the HD Map is queried by the routing module to plan high level routes. [GitHub] Apollo\u2019s HD Map has both an onboard client component as well as an offboard server component. There are two possible interpretations of the reference architecture documentation as it pertains to navigation. One possibility is that all map data is stored onboard in the Localization module. Another is that map and routing functions are performed off the vehicle platform. The maps are then remotely sent to the vehicle to contribute to the vehicle\u2019s External World Model.","title":"HD Map"},{"location":"assignment1/#monitor","text":"The Monitor module provides status checks of both hardware and software components of the system. This subsystem surveils all the modules of the vehicle, as well as hardware to ensure they are working as intended. This data is passed to the Dreamview for the passenger to easily view the status of the system. [GitHub] The Monitor component of Apollo has a similar function to Platform Fault Management in the reference architecture.","title":"Monitor"},{"location":"assignment1/#dreamview","text":"Dreamview , Apollo\u2019s HMI module, provides a UI in the form of a web application that allows developers or vehicle passengers to visualize the data produced by other subsystems. Given the inputs of the other modules, Dreamview produces a three-dimensional representation of the vehicle including the current location and planned path. Additionally, using data from the Monitor module, Dreamview displays the status of the components and hardware of the vehicle. [GitHub] Apollo\u2019s Dreamview visualization interface is an example of a service that is performed offboard in the reference architecture, in this case both tele-operation and remote monitoring.","title":"Dreamview"},{"location":"assignment1/#guardian","text":"The Guardian module serves as an \u201caction center\u201d that will only react in case of module failure. Using reports sent by the Monitor, the Guardian may do one of two things. If all modules are working as expected, the Guardian allows the process to continue normally. If the Monitor detects failure of some form, the Guardian works to handle the failure by preventing controls from reaching the CanBus, then stopping the vehicle. The Guardian manages two main types of shutdowns. If the sensors are operating normally and do not detect any obstacles the vehicle will enter a controlled slow stop by applying light breaking. In the second scenario, if the sensors are not operating normally, the Guardian applies heavy breaking to bring the car to an immediate stop. [GitHub] Apollo\u2019s Guardian module works with the Monitor module to produce the functions of Platform Management in the reference architecture.","title":"Guardian"},{"location":"assignment1/#localization","text":"The Localization component is a low-level module that provides localization services to other components. Depending on the hardware available in the car, this module can use a combination of GPS, an inertial measurement unit, and LiDAR. The localization component outputs an estimate of the vehicle's location. [GitHub] Apollo\u2019s Localization module is equivalent to the Localization module in the reference architecture.","title":"Localization"},{"location":"assignment1/#control","text":"The Control component generates control commands for the vehicle to create a \u201ccomfortable driving experience.\u201d Using the localization of the vehicle, the car status, and the trajectory created by the Planning module, commands are created by various algorithms depending on the scenario. Commands include those for the steering, brakes, and throttle, to be used by the chassis. These commands are passed to the CanBus to control the vehicle hardware. [GitHub] Apollo\u2019s Control module is comparable to the Control module in the reference architecture. However, the reference architecture considers several decision-making functions to be within the Control subsystem whereas Apollo\u2019s Control module is separate from its Planning and Guardian, for example.","title":"Control"},{"location":"assignment1/#canbus","text":"CanBus works closely with the Control module, acting as the interface between the software system and the physical vehicle chassis. In one direction, the module uses a suite of sensors specific to the vehicle model to report the status of the car to Control. In the other direction, it executes the actions required to actualize the commands sent from Control, such as changing direction, engaging brakes, and accelerating. [GitHub] The CanBus module onboard the Apollo software system is one implementation of the Vehicle Platform Abstraction component of the reference architecture.","title":"CanBus"},{"location":"assignment1/#concurrency","text":"The Cyber RT framework that underlies the other modules of the software platform provides several mechanisms for concurrency. At a high level, it implements a \u201ctask\u201d abstraction to describe asynchronous computing operations. Beyond this, Cyber RT provides different resource scheduling algorithms that developers can choose from to better suit specific scenarios, as well as a coroutine implementation called \u201cCRoutine\u201d that optimizes system resource and thread utilization. [GitHub]","title":"Concurrency"},{"location":"assignment1/#architecture-styles","text":"The primary architectural style present in the Apollo software platform is publish-subscribe, which allows the various subsystems to interact in a well-defined and loosely coupled manner. As discussed previously, the Apollo Cyber RT system acts as a message broker in this architecture. Cyber provides an implementation of \u201cchannels\u201d as a mechanism of data communication between the other modules, which can act as either \u201creaders\u201d or \u201cwriters\u201d in respect to a given channel. [GitHub] Acting as a writer, a module publishes messages to a channel, consisting of structured data such as commands, events, or sensor data. When acting as a reader, a module has defined interfaces that handle processing and reacting to messages on subscribed channels according to registered function callbacks. [GitHub] There does not seem to be any limit to how many channels a module can act as a reader or writer on, but each writer interface defines a unique channel to enforce isolation by message \u201ctopic\u201d. There are many benefits to the publish-subscribe model in a system as complex as Apollo. By relying on broadcast events, modules can send out commands or data to other parts of the system without having to lose process control or wait for responses. This is crucial in the domain of autonomous driving as continuous operation of all subsystems is critical for the continuing operation and safety of the vehicle and its occupants. From a development standpoint, the architecture also allows for the various subsystem modules to be independent and isolated, only interacting by certain strict mechanisms and interfaces, and keeping them loosely coupled. It also simplifies future evolution of the system, since the strict interfaces and loose coupling make it easier for modules to be split, replaced, or even removed, and for new modules to be added. However, publish-subscribe is not the only communication mechanism present in the platform, and while it is prevalent enough to define the overall architecture there are certain components that interact according to other patterns. In addition to the publish-subscribe facilities, Cyber RT also provides interfaces for client-server-style interaction, for scenarios requiring two-way request-response communication. [GitHub] One case where this is used seems to be in making ad hoc queries to the HD Map module. Finally, it is worth noting that by using these mechanisms, the Control and CanBus subsystems implement a process control pattern. In this sense, the Control module acts as the controller, creating execution plans for car actions based on requirements and data from the other modules, while the CanBus acts as the process, interfacing with the actual physical vehicle to actualize the commands from Control as well as providing it with feedback from chassis sensors.","title":"Architecture Styles"},{"location":"assignment1/#use-cases","text":"Figure UC0: Sequence diagram of the \u2018loop\u2019 that the Apollo system goes through as it creates the optimal path for the vehicle to go. It is described in the text. Figure UC0 displays how the system logic works in a loop of sorts, in that this process continues to be performed while the vehicle is driven, and the appropriate modules are working. The Localization module must first estimate the location of the vehicle and publish it to Cyber RT, which brokers the data to all subscribed modules. Routing and Storytelling both use the localization data, as well as queried map data from HD Map, to generate a route and a story, respectively. These are published to and brokered by Cyber RT. After receiving data from the sensors, the Perception module then determines obstacles, lanes, and traffic light status (if applicable), which is again published to and brokered by Cyber RT. The Prediction module uses this Perception data, as well as Localization, Routing, and the previous trajectory of Planning, to predict obstacle trajectories and prioritize them. These are published to Cyber RT, then sent to the Planning module; given Localization, Perception, Prediction, Routing, and Storytelling, as well as queried map data, the optimal trajectory is created by Planning. It is published to Cyber RT, then brokered to Prediction and Control. The Control module then generates the appropriate control commands, which are published. If the system is in a good state, then the CanBus retrieves these controls, sending them to the hardware, and publishes chassis data. While these processes are running, the HMI retrieves data using Cyber RT\u2019s channels, displaying them to the user or driver. The Monitor may also retrieve these data, processing them and publishing a report that details the state of the modules; Cyber RT then sends the report to both the HMI and Guardian. The HMI displays the report\u2019s results, while the Guardian ensures that there are no issues. If there are any failures, however, then the Guardian will enact its procedure to handle it as described in Subsystems .","title":"Use Cases"},{"location":"assignment1/#use-case-1-lane-following","text":"The first use case is the default lane following. In this use case, the vehicle is to stay within its lane and follow another car at a safe distance. First, hardware sensors described in Subsystems feed data to the perception module. The perception module then identifies lane lines as well as the other car, but does not identify any traffic lights in this case. Sensor fusion takes the labelled objects and sensor data to assign the car ahead with a distance and velocity. Lane lines are marked with their distance away. This information is published to Cyber RT and picked up by the prediction module. By identifying that there are currently no traffic lights ahead, the prediction module characterizes the scenario as \u201ccruise\u201d. The leading car is assigned priority \u201ccaution\u201d as it may affect the ego car\u2019s trajectory. Eventually, a trajectory for the leading car is predicted and, in this case, that trajectory is continuing in the lane and either slowing down or speeding up. This trajectory is published to Cyber RT and picked up by Planning. Planning uses the predicted trajectory of the leading car to produce a \u201ccollision-free and comfortable\u201d trajectory for the ego car. In this use case, the trajectory would be to direct the car within the lane and at a speed similar to the leading car. This trajectory is published to Cyber RT and picked up by the control module. The control module uses the planned trajectory along with localization information and car status coming from the CanBus to produce control signals for steering, brakes and throttle. In this case, it would be expected that the steering signal would only change the position of the wheels to follow the lane. Throttle and brake control signals should be mostly neutral as well unless the car ahead is stopping or accelerating quickly. Figure UC1: Sequence diagram for the lane following use case, focusing on the system\u2019s process from Perception to CanBus.","title":"Use case 1: Lane following"},{"location":"assignment1/#use-case-2-unprotected-left-turn","text":"The second use case to be considered is the \u201cUnprotected Left\u201d scenario described in the details of the Planning module of Apollo 5.5 [GitHub] ; it is one scenario relating to a traffic light that remains within the Planning module [GitHub] . In this use case, the vehicle is to turn left through an intersection with a traffic light to continue to its destination; the term \u201cunprotected\u201d refers to how there is no distinct left/right turn light; the vehicle must yield to oncoming traffic. Specifics of what the vehicle should do are detailed in the README of 5.5\u2019s Planning module. Figure UC2: Sequence diagram of the Planning module\u2019s determination of the optimal trajectory for the given use case of \u201cunprotected left turn.\u201d Figure UC2 highlights the process that the Planning module runs to determine the optimal trajectory for the vehicle. The various inputs that were brokered by Cyber RT are stored; then, the \u201cScenario Decider\u201d determines the scenario that is to be handled: Traffic Light, Unprotected Left. This is done by noting the traffic light status that was determined by Perception. Using this scenario as well as the inputs (particularly route and map), the module plans a path for the vehicle; this is then used by the speed planner (in addition to the input) to determine an optimal speed. If the vehicle needs to stop, then it should slow or stop; otherwise, it should first \u201ccreep\u201d forward to determine if no \u201cobstacles\u201d are present. Once in the intersection, it must yield to oncoming vehicles by slowing down, or otherwise continue driving safely at the appropriate speed for the intersection. This is done by taking note both of obstacles noted by Perception as well as the corresponding predicted trajectories and priorities given by Prediction. Using the path and speed, a trajectory is made and finally sent for other modules such as Control to access.","title":"Use case 2: Unprotected left turn"},{"location":"assignment1/#lessons-learned","text":"This report was a complex undertaking and as such we learned a lot in the process of completing it. As it was our group\u2019s first major project together, we learned in the process of it each other\u2019s strengths and weaknesses and styles of working, which will hopefully make planning for future deliverables easier. In respect to the topic itself, we realized just how revealing quality documentation can be, and how much it can reveal about a system on close reading, though its accuracy remains to be seen. To that end, it took us some time to realize how crucial documentation for older versions of Apollo would be to our understanding of the platform, and initially ignoring anything that was not marked for the latest version slowed down initial work significantly.","title":"Lessons Learned"},{"location":"assignment1/#glossary","text":"L4 Autonomy: SAE International has created a standard, \u201cJ3016 Levels of Automated Driving.\u201d These levels range from Level 0 (no automation) to Level 5 (full autonomy). Level 4 (L4) is described as highly automated with features able to drive the vehicle in limited conditions, compared to Level 5 which may drive in all conditions. [SAE] HMI: Human Machine Interface IDPS: Intrusion Detection and Prevention System [Baidu] IVI: In-Vehicle Infotainment LiDAR: Light Detection and Ranging","title":"Glossary"},{"location":"assignment1/#references","text":"Apollo Auto. \u201cRobotaxi: Autonomous Driving Solution.\u201d Baidu (2020). Retrieved from https://apollo.auto/robotaxi/index.html. Apollo Auto. \u201cApollo Cyber Security.\u201d Baidu (2020). Retrieved from https://apollo.auto/platform/security.html. ApolloAuto. \u201cApolloAuto/apollo: An open autonomous driving platform.\u201d GitHub. Last accessed February 18, 2022. Retrieved from https://github.com/ApolloAuto/apollo. ApolloAuto. \u201cPlanning README at 5.5.0.\u201d GitHub (2020). Retrieved from https://github.com/ApolloAuto/apollo/blob/r5.5.0/modules/planning/README.md. Behere, Sagar, and Martin T\u00f6rngren. \u201cA functional reference architecture for autonomous driving.\u201d KTH The Royal Institute of Technology, Brinellv\u00e4gen 83, Stockholm SE-10044, Sweden (2015): 143. Retrieved from https://www.sciencedirect.com/science/article/abs/pii/S0950584915002177. Shuttleworth, Jennifer. \u201cSAE Standards News: J3016 automated-driving graphic update.\u201d SAE International (January 7, 2019). Retrieved from https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic.","title":"References"},{"location":"assignment2/","text":"The Concrete Architecture of Apollo Click here to access this report as a PDF. (Requires Queen's University login.) Click here to access the accompanying presentation slides. (Requires Queen's University login.) Abstract As an open-source autonomous driving platform, Apollo understandably is a complex system. Having developed greatly over the years, its architecture has changed over time; thus, its concrete architecture may vary from the conceptual architecture derived from its documentation. To derive the concrete architecture, the Understand 5.1 tool, GitHub repository, and a publish-subscribe communication visualization diagram were utilized to determine dependencies between modules. This process confirmed the publish-subscribe, process-control, and client-server architectural styles determined in the conceptual architecture, but also added three new modules\u2014Drivers, Common, and Task Manager\u2014as well as updated the Map module; various discrepancies were found in the Reflexion Analysis process, including direct code dependencies. The Prediction submodule was also studied in this process, revealing that this module utilizes a combination of the object-oriented and publish-subscribe styles in its predicting of obstacle trajectories, with four core sub-modules: Container, Scenario, Evaluator and Predictor. Introduction Apollo is an open-source platform dedicated to the development and testing of autonomously driving vehicles. As a system that values security and safety while maintaining good performance, Apollo\u2019s developers have created a complex system that largely uses the publish-subscribe style. The system contains a variety of subsystems that provide its functionality while satisfying its requirements, including a Perception module to determine obstacles and details, a Prediction module to predict how the surrounding world and obstacles may change, a Planning module that plans the vehicle\u2019s trajectory, and a Control module that transforms the trajectory into commands for the vehicle to deploy. A conceptual architecture was created by studying a reference architecture [Behere and T\u00f6rngren] as well as utilizing Apollo\u2019s documentation. Although the conceptual architecture may describe the system of Apollo to a degree, there are always limitations to what may be extracted via a reference architecture or system documentation. It may deviate from the reference architecture; the documentation may be a work in progress for the system\u2019s current state, and/or omit minor dependencies. Thus, to fully understand Apollo, one must study its code to determine its concrete architecture. To derive the concrete architectures of both Apollo as a whole and our chosen subsystem, Prediction, we used the Understand tool at version 5.1, as well as a graph visualization of the publish-subscribe communication within the system, and in-depth investigation of the source code. Dependencies found within these visualizations were compared to our conceptual architecture, and discrepancies were added or removed as necessary. These discrepancies were studied in further detail to understand them in various ways, including their purpose and timing. Studying Apollo\u2019s source code reveals three additional modules: Drivers, Task Manager and Common, as well as a module, Map, which contains a component of our conceptual architecture, HD Map, as a sub-component. In addition, although publish-subscribe remains largely what the system is built on, Apollo utilizes direct dependencies in its functionality, particularly to the Map module as well as a Common module, and various calls to include files from different components that help in other components\u2019 function. Derivation Process Figures 1 and 2 visualize the conceptual architecture that was derived from Apollo documentation and the reference architecture. Figure 1 highlights the dependency relations between various modules, while Figure 2 emphasizes the architectural style that Apollo is largely built upon: the publish-subscribe style, where modules publish and subscribe to topics of interest as their main form of communication with one another. Figure 1: Dependency relations of the Apollo architecture, as determined in the conceptual architecture retrieval process. (Corrected to match conceptual architecture report text.) Figure 2: Communication flow within the Apollo conceptual architecture. The conceptual architecture retrieved from various Apollo- and autonomous driving-related sources is an essential aspect of determining and understanding the concrete architecture used by the system. The process of deriving this conceptual architecture, as well as its details, may be found in our previous report. [OBEIA] Understand, Publish-Subscribe and Reflection One way to derive the concrete architecture of a system is by studying its source code, taking note of when modules and files within them reference other modules, suggesting a dependency. One method of doing so is via the Understand program. Using a file for this program provided by our instructor, we applied Understand 5.1\u2019s dependency diagram tool; this process produces a visual of the dependencies of the system and allows one to view their specifics. However, due to the publish-subscribe style relying upon a central bus, many dependencies are obscured. To mediate this, our instructor provided another diagram, shown in Figure 3, representing the communication between modules in this style. Using these diagrams, we regularly considered our conceptual architecture, adding and removing dependencies as necessary; in considering these dependencies within Understand, we removed test files that did not affect the system itself. When reviewing discrepancies, we also discerned their purpose, timing, and attribution, if applicable, provided in Reflexion Analysis. In our study of the source code, three new modules or sub-components were found: a common module, a task manager, and drivers. Further, rather than HD Map, there is a \u201cMap\u201d module containing the HD Map as a sub-component. These modules are described in further detail with other subsystems of Apollo, within the Concrete Architecture section. The dependency diagrams and publish-subscribe visualization highlight many different dependencies through the system, notably various dependencies that do not occur within the publish-subscribe communication flow. Some dependencies recorded in our conceptual architecture were missing, whereas many unanticipated dependencies were found. Figure 3: Publish-subscribe communication visualization within Apollo. Concrete Architecture Figures 4 and 5 present the concrete architecture of Apollo\u2019s software system as code dependencies, Figure 6 presents the architecture as messaging dependencies between modules. The architecture and interactions are described further in the following sub-sections. Figure 4: Apollo system inter-module code dependencies, according to Understand 5.1. Figure 5: Simplified view of Apollo inter-module dependencies. Figure 6: Publish-subscribe communication of the concrete Apollo architecture. Modules and Subsystems Cyber RT Apollo\u2019s architecture is built around a custom runtime framework called Cyber RT . Cyber RT has many responsibilities as both a runtime component and a base library for other system modules. At runtime, Cyber manages module loading and most of the inter- and even intra-module communication, through facilities for either publish-subscribe messaging or client-server interaction. Cyber RT also provides code dependencies, including runtime base classes, and utilities for file operations, logging, timing, concurrency, and asynchrony. The publish-subscribe functionality is done through a \u201cchannel\u201d abstraction over multiple transport types, allowing it to be suited for various deployment scenarios. The cyber::Reader class template allows construction of subscribers to a channel and to receive messages on it, either declaring a callback function to trigger when a message is received or allowing messages to be cached for later observation. In many cases, the callback function is simply to store the message so a reference to the latest one is available for use. Publishing to a channel is handled by specializations of the cyber::Writer class template, which can write a single message type to a single channel. On the wire, exchanged messages are byte streams in the protocol buffer (protobuf) encoding format. Each module includes a collection of .proto files which define the messages it sends. Code is generated from the .proto files at build time, which is used by the publishing module for message serialization, and by the subscribing module(s) for deserialization. The Apollo runtime modules are made up of one or more Cyber RT \u201ccomponents\u201d. There are two component base classes that a module can inherit from: cyber::Component (and its various partial specializations) and cyber::TimerComponent . Components inheriting from cyber::Component can declare zero to four message types to listen for and have their main processing logic automatically triggered when a message is received on those channels. Components inheriting from cyber::TimerComponent are instead triggered on certain time intervals. Either type of component can declare additional Reader s, and as many Writer s as required. All components must be registered with Cyber RT to operate. The fundamental nature of Cyber RT means that all other operating subsystems of Apollo depend on it. Common While not a running module that provides specific functionality to the system, the Common module contains useful code that other modules may rely on. The contents include global constants (in the form of gflags ) for topic names, vehicle configuration and data, access to system-wide parameters through a key-value database, latency recording and monitor logging, operation statuses, protocol buffer definitions that see use across the entire system, various math and parsing utilities, and a class that models the overall vehicle state, among others. [GitHub] As it is not a runtime module, Common does not exist as a Cyber RT component. Other than Cyber RT, every analyzed Apollo subsystem relies on Common. Drivers The Drivers module contains code for interfacing with the various hardware components of the Apollo vehicle platform. It contains CAN client code, used both for reading from typical chassis sensors and controlling the vehicle. Additionally, it contains interfaces for the more advanced sensing equipment required for autonomous vehicle operation, including cameras, microphones, LiDAR, radar, and GNSS. These sensors are bridged into the rest of the system by Cyber RT components that write their readings to channels for other modules to read. Some Drivers components are subscribed to messages from the Localization and Canbus modules, relying on them for operational information. Guardian Guardian acts as Apollo\u2019s emergency response system, implemented as a Cyber RT TimerComponent . All messages from Control to Canbus pass through Guardian, which decides whether to block them based on vehicle and system status it receives from Canbus and Monitor. In the event of a system error, Control commands will be blocked, and Guardian will instead direct Canbus to bring the vehicle to a stop. Monitor Monitor is a cyber::TimerComponent that regularly checks the status of the hardware and software of the system, using various mechanisms including OS-level process checks, and status messages on most Cyber RT channels. It reports results on the SystemStatus channel and is also able to directly update Dreamview. Dreamview Apollo\u2019s HMI module, Dreamview , includes a JavaScript frontend that allows users to visualize the data produced by other subsystems, and an on-board backend. Dreamview reads messages from all other modules and produces a three-dimensional representation of the vehicle including the current location and planned path and displays the status of the system components and hardware. Additionally, Dreamview contains a map service that other modules rely on, and an interface to allow certain HMI actions to be carried out. Perception The Perception subsystem takes input from physical sensors mounted on a vehicle, including cameras, LiDAR sensors, and radar, over channels from the Drivers module. This subsystem outputs decisions on the state of nearby traffic lights and a list of objects which are labelled with their type, distance from the vehicle, and velocity. [GitHub] The module is quite complex and includes ten different Cyber RT components. Prediction The Prediction subsystem predicts the future movements of objects identified by the perception module, implemented as a cyber::Component that is triggered by the publishing of PerceptionObstacles messages. [GitHub] This module is described in more detail in the Subsystem: Prediction section of this report. In addition to Perception, the module reads from Storytelling, Map, and Localization subsystem channels. Planning The Planning subsystem aims to plan the exact route of the vehicle. It first plans short term goals such as staying in a lane, then plans the future trajectory of the vehicle. The Planning module may request a new routing computation if unable to follow the original route. [GitHub] Planning is subscribed to seven channels throughout the system; it is directly dependent on Dreamview, Routing, Localization, Prediction and Map. Localization The Localization module provides localization services to the platform. This module consists of three different Cyber components that each implement a different localization strategy on what sensors are available to the vehicle, the data from which it reads from channels of the Drivers module; providing an estimate of the vehicle's location as output. [GitHub] Map The Map module includes the HD Map found within our conceptual architecture, which served as a query engine for the other modules to provide detailed road information. [GitHub] The Map also includes a PnC Map and Relative Map. [GitHub] It is subscribed to Localization, Canbus, and Perception topics, and has code dependencies on Routing and Planning. Routing The Routing subsystem generates navigation paths, typically from the vehicle\u2019s current location to the passenger\u2019s destination. Another module can request for routing by publishing a RoutingRequest , which triggers the RoutingComponent (a child of cyber::Component ). Routing\u2019s logic additionally makes direct use of Map to produce a RoutingResponse which can be used by other modules, notably Planning. [GitHub] Canbus Acting as the interface between the software system and the physical chassis, Canbus works closely with the Control and Guardian modules, subscribing to and actualizing commands from one of them according to a configuration flag. Canbus also reports the chassis status to the rest of the system and relies heavily on code in Drivers in its operation. [GitHub] Storytelling The Storytelling subsystem is a scenario manager intended to coordinate inter-module actions. This module creates \u201cstories\u201d: complex scenarios that may be used by other modules. [GitHub] This sub-system does not subscribe to any module topics but does write to topics of its own; it is dependent directly on the Map module. Control The Control subsystem employs various algorithms to generate control commands for the steering, brakes, and throttle, depending on the scenario the vehicle is in. Control passes the commands to the Canbus to control the vehicle hardware. [GitHub] It is subscribed to topics from Planning and Canbus; it both subscribes to topics of and directly depends on Localization. Task Manager The Task Manager contains various routing managers to be employed by the system as required. It writes to a RoutingRequest channel if the routing process needs to be redone. [GitHub] It is subscribed to topics from the Routing and Localization modules and is directly dependent upon Dreamview and Map. Architectural Styles Recovering Apollo\u2019s concrete architecture confirmed that publish-subscribe served as the primary form of communication between modules; the method of how it is applied was described in detail previously in the Cyber RT subsystem description. The process-control pattern was confirmed in the concrete architecture, with the Control module acting as the controller, while Canbus acts as the process; here, the Control module creates execution plans, which the Canbus reads and actualizes for the hardware, then provides Chassis data (i.e., feedback) to Control. Finally, the client-server style of interaction via Cyber RT was confirmed; the Cyber RT API for Developers discusses the process in detail, in that it implements two-way communication in this fashion where a node sends a request to receive a response. [GitHub] The Routing channels RoutingResponse and RoutingRequest are one such example of this style. Reflexion Analysis Upon comparison between our conceptual publish-subscribe architecture and the concrete one, several discrepancies were identified in inter-module messaging dependencies. Table 1 describes the expected dependencies that were found to be absent in the concrete architecture. Table 2 describes the concrete dependencies that were not expected in the concrete architecture. Table 1: Conceptual dependencies absent in concrete architecture. Listener Module Talker Module Discrepancy Details Control Storytelling The expectation for Control having a dependency on Storytelling came from the Storytelling documentation listing Control as an example of a module that might subscribe to a story. At this time, there is only one story implemented in Storytelling, which does not require Control to be subscribed. Since any module could subscribe to Storytelling as more stories are implemented, this dependency might exist in the future. Routing Map This expected dependency is not necessarily absent, it instead takes a different form than initially expected. It was expected that communication between Routing and Map would be carried out over Cyber\u2019s publish-subscribe or client-server transports. Instead, it appears to be a direct code dependency. Storytelling Localization In 2020, this dependency was recorded in the README file for Storytelling ( 09a4f00 ); however, study of the code at this period of time reveals direct dependencies to Planning and Prediction that have been removed since, but not Localization either through code or messaging. Storytelling Map This expected dependency is not necessarily absent, it instead takes a different form than initially expected. It was expected that communication between Storytelling and Map would be carried out over Cyber\u2019s publish-subscribe or client-server transports. Instead, it appears to be a direct code dependency. Table 2: Dependencies found in concrete architecture not expected by conceptual. Listener Module Talker Module Discrepancy Details Drivers 1 Canbus The gnss::RawStream class of the GnssDriverComponent is subscribed to Chassis messages. On a timer, it extracts speed data from the message and writes a corresponding wheel velocity command to the command stream. Drivers 1 Localization The ContiRadarCanbusComponent is subscribed to LocalizationEstimate messages to extract the vehicle's pose data. Specifically, it uses orientation and linear velocity to calculate a speed and yaw rate, as required by the radar hardware. Guardian Canbus Guardian is subscribed to Chassis messages from Canbus so it can check for sonar faults and obstacles in the event of an emergency stop when safety mode is triggered. If either are found, the vehicle is supposed to make a hard emergency stop, otherwise a soft one can be made. However, since a change in June 2018, these flags are ignored pending \u201chardware re-alignment.\u201d ( 97b0b3c ) Guardian Control Guardian listens for ControlCommand messages from Control. When the system is not in safety mode, the ControlCommand s are wrapped in a GuardianCommand and published for Canbus to receive. When safety mode is enabled, the commands are blocked from reaching Canbus. Our assumption had been that the safety mode control logic existed in Canbus, which listened for commands from Control and a safety mode state from Guardian and considering both, rather than the commands passing through Guardian. Localization Drivers 1 The Localization module relies on sensor data from Drivers in the form of GnssBestPose , PointCloud , CorrectedImu , and InsStat messages. Map Canbus Chassis messages from Canbus are listened for by the RelativeMap submodule of the Map component. In part of creating the relative map, it uses Chassis and LocalizationEstimate data to update the vehicle state. Map Localization LocalizationEstimate messages from Localization are listened for by the RelativeMap submodule of the Map component. In part of creating the relative map, it uses Chassis and LocalizationEstimate data to update the vehicle state. Map Perception PerceptionObstacles messages from the Perception module that contain lane marker data are used by the RelativeMap submodule of the Map component to create one or more navigation paths in the relative map. Monitor Canbus Initial analysis during the development of the conceptual architecture concluded that Monitor\u2019s monitoring of other Apollo modules was primarily achieved by channel utilities provided by Cyber RT, and operations at the operating system level such as checking system resource usage and that processes are running. While those are all methods that Monitor employs, it also subscribes to topics of various modules to look out for anomalous activity. Control Dreamview Drivers 1 Localization Map Perception Planning Prediction Perception Drivers 1 The Perception module receives LiDAR and radar data in the form of PointCloud and ContiRadar messages, respectively, from the Drivers module. Planning Canbus Planning listens for Chassis messages containing details of the vehicle state. The chassis data is combined with data from the other subscribed inputs as a LocalView , which \u201ccontains all the necessary data as planning input.\u201d This input is not listed as a data input in the Planning documentation, so it was not considered in the conceptual architecture. Prediction Storytelling Prediction is subscribed to Stories messages from Storytelling, in order to be a part of cross-module coordination when a story scenario occurs. Prediction was not listed in the Storytelling documentation as an example subscriber, but any module could potentially be a story subscriber, depending on which stories have been implemented. The only story implemented so far is CloseToJunction , which requires Prediction. Task Manager 2 Localization The Task Manager listens for LocalizationEstimate messages, which it uses for vehicle positioning data. The vehicle coordinates are used to determine the distance to waypoints in cycle and dead-end routing tasks. Task Manager 2 Routing The Task Manager subscribes to RoutingResponse messages to confirm that routing requests that it has made have succeeded. Drivers had not been included in the conceptual architecture as a module, as such all publish-subscribe interactions involving it appear as a divergence. Task Manager had not been included in the conceptual architecture as a module, as such all publish-subscribe interactions involving it appear as a divergence. Code Dependencies Even in Apollo\u2019s publish-subscribe architecture, the modules and subsystems are not fully isolated or independent. One category of such code dependency makes complete sense, which is any dependency on the Common or Cyber modules. As described previously, these modules both provide utilities and runtime functionality, and are meant to be relied on in this way. Another category of inter-module code dependency comes from the use of protocol buffers. Every module that publishes messages includes .proto definitions that are used to generate protobuf serialization code at build time. Subscribing modules that need to deserialize the protobuf messages must rely on this generated code as well, which can be seen as #include s for files ending in .pb.h . This sort of dependency between modules is a requirement of the system, and the benefits of using strict schemas enforced by generated code at the expense of full module isolation far outweigh the benefits of full isolation but requiring either unstructured messages or duplicated message class code. However, one case where this is less expected is in the VehicleStateProvider class of the Common module, which depends on Chassis and LocalizationEstimate protobuf code from Canbus and Localization, respectively, as well as in the accompanying vehicle_state.proto which relies on chasis.proto and pose.proto from the same respective modules. It is unusual for a common module to depend on more specific functional modules, even in this way. Other code dependencies that were found are detailed in Table 3. Table 3: Other inter-module code dependencies. Dependent Module Dependency Module Dependency Details Canbus Drivers The Canbus module depends heavily on the Drivers module, specifically the drivers/canbus/ subdirectory. The drivers/canbus/ directory contains CAN client code, such as the base CanClient class, specific CAN client implementations that inherit from CanClient , and the CanClientFactory that registers the clients. The CAN client code used to be part of the Canbus module but was moved to drivers/ since different sensors using the protocol all share use of it. ( 10fb2bf ) Common Localization Common declares a dependency on the localization_gflags.h file in the implementation of the VehicleStateProvider class. The value of this flag is used to choose how to determine the linear acceleration and angular velocity of the vehicle. It is, however, quite odd to see a \u201ccommon\u201d module depend on a specific subsystem. Control Localization The LonController class in the Control module includes the localization_gflags.h file but does not appear to make use of the flags anywhere. The inclusion dates to Apollo 1.0 and the earliest commit in the codebase, but the flags go unused there and in every revision since. The dependency is unnecessary. Dreamview Map Dreamview\u2019s MapService makes use of both hdmap::PncMap and hdmap::HDMap (via hdmap::HDMapUtil ), querying both map models for routing information and road features such as lanes, speedbumps, signs, etc. Additional use of Map classes is used in simulation functionality. Map Planning The hdmap::PncMap class includes planning_gflags.h from the Planning module since December 2017. ( 4abd4e3 ) The class logic continues to make use of these flags. Map Routing At one time, the hdmap::PncMap class was made dependent on one of the flags from routing_gflags.h . ( 1effd0c ) However, the use of this flag was later modified, then removed entirely. ( b3ce40c ) No other Routing flags are used by this class, making the dependency unnecessary. Monitor Dreamview The MonitorManager class has a dependency on the dreamview::HMIWorker , which is a singleton object, as well as on dreamview_gflags.h . The HMIWorker singleton is used to update configs and monitored modules when the HMI status reports a mode change. Perception Map Perception contains the perception::map::HDMapInput class, which is a thread-safe singleton wrapping HDMap for use by the many subcomponents of Perception, including various sensors that need map data, and for sensor fusion. The wrapper includes hdmap.h , hdmap_common.h , and hdmap_util.h . Perception Prediction The Perception module\u2019s multi-LiDAR fusion engine and evaluator manager make use of classes from the Prediction module. The former using the obstacles and pose containers and the latter relying on the semantic LSTM evaluator. This appears to be a case of specialized code reuse for the evaluator use case and not a runtime module interaction. Planning Dreamview planning::OpenSpaceRoiDecider declares a dependency on dreamview::MapService , however it is unclear why. It does not appear to be used. It is possible that the dependency being unused, or the location of its use, is lost in the size of the commit it was introduced in. ( 6db2a1b ) Planning Map The Planning module makes significant use of elements of all three submodules of the Map system, relying on the HD Map, PnC Map, and relative map for road and environment details in navigation planning. Planning Prediction AutotuningMLPModel in Planning extends prediction::network::NetModel , which is a base class for implementing machine learning network models. This is a case of code reuse not module interaction at runtime, but the base class could be considered for extraction into a common library. Planning Routing The planning::ReferenceLineProvider class declares a dependency on routing_gflags.h from the Routing module, since the class logic relied on one of the flags. ( b3ce40c ) The method where the flag was used was later made unreachable, ( c488562 ) and the dead code was removed some time later. ( c0331f9 ) However, the dependency was not removed, despite now being unnecessary. Prediction Map The Prediction module makes use of HD Map as part of its prediction map and semantic map. The primary interaction appears to be positioning and predicting the movement of obstacles relative to lanes, with lane details coming from Map. Routing Map 1 The routing::Routing class declares a dependency on hdmap_util.h from the Map module. It uses a utility from there to get the routing map file to construct a Navigator , and another to receive a pointer to the HDMap object, which it uses to query lanes and parking spaces. Storytelling Map 1 The storytelling::CloseToJunctionTeller class makes use of the hdmap::HDMapUtil class querying details of the surroundings when approaching an intersection. Task Manager Dreamview task_manager::CycleRoutingManager uses a dependency on dreamview::MapService to construct lane waypoints when getting new routing at the beginning/end of a cycle. Task Manager Map Task Manager\u2019s DeadEndRoutingManager and ParkingRoutingManager declare several dependencies on HD Map classes but make no use of them. Like the earlier Planning/Dreamview dependency this was introduced in a very large, squashed commit and it seems likely that the unnecessary dependencies went unnoticed. ( 6db2a1b ) This dependency is notable since in the initial conceptual architecture analysis it was assumed that the communication was done either by the pub-sub channels or Cyber RT\u2019s client-server mechanism. However, it appears to simply be a code dependency. Subsystem: Prediction In studying the architecture of Apollo, we chose to study one of its core subsystems, the Prediction module, in further detail. This entailed deriving its conceptual architecture, and then forming its concrete architecture, applying the reflexion analysis in the process. Subcomponents Container The Container stores input data that the Prediction module listens for from subscribed topics; currently, these are Perception obstacles, Planning, and Localization. [GitHub] Scenario The Scenario sub-module defines scenarios that the ego vehicle may be in; currently these scenarios are cruising , which includes lane keeping and following, and junction , which includes intersections with traffic lights and/or stop signs. [GitHub] Evaluator The Evaluator separately predicts the path and speed of each obstacle and evaluates them by outputting a probability that they occur by using a given model. It uses a variety of possible evaluators, and most apply machine learning to determine these probabilities; the models utilized in these machine learning evaluators include RNN, MLP, CNN-1d and social LSTM. For example, the Semantic LSTM Evaluator, used for \u201ccaution\u201d-level obstacles, generates short-term trajectory points via CNN and LSTM. [GitHub] Predictor The Predictor generates predicted trajectories. A variety of possible predictors are supported, including empty , for obstacles with no predicted trajectories; single lane , where they move along a single lane in \u201chighway navigation mode;\u201d lane sequence , where they move along the lanes; move sequence , moving along the lanes \u201cfollowing its kinetic pattern;\u201d free movement ; regional movement , moving in a possible region; and junction , moving toward junction exits. An interpolation predictor computes the likelihood of creating posterior prediction results after all evaluators have run, intended for \u201ccaution\u201d-level obstacles. An extrapolation predictor creates an 8 sec trajectory, extending the Semantic LSTM Evaluator. [GitHub] Conceptual Architecture To derive the conceptual architecture of the Prediction module, we studied its documentation. The documentation, found in the module README file, provided details on each core sub-module, as well as a diagram presenting their communication and control flow. Figure 7: Conceptual architecture of the Prediction module. Concrete Architecture As with the concrete architecture of the full system, we studied the dependency diagram formulated by Understand to derive specific dependencies of the system. This, however, has limitations regarding publish-subscribe communication between Prediction\u2019s sub-modules and other modules in the system, as the provided publish-subscribe visualization does not go into such detail. However, a study of the main sub-modules\u2019 code presents that the Evaluator and Predictor modules have publish-subscribe dependencies to other modules. Figure 8: Concrete architecture for the Prediction module. Figure 9: Publish-subscribe communication focused on the Prediction module. Architectural Styles The visual representation of the subcomponent communication reviewed in the conceptual architecture derivation process led us to conclude that the object-oriented style would fit the architecture. This is as the sub-modules would need to know the identities of one another. The Container identifies and protects specific input data; the other sub-modules may use these specific data, i.e., they need to know which data is which, and from which source it is from. This is supported by direct includes in the code to specific Containers in the concrete architecture. In addition to the object-oriented style, Prediction employs some publish-subscribe communication, both in terms of inter-module and intra-module communication. In particular, the Evaluator and Predictor listen for specific topics, which can be seen in their submodule code. Reflexion Analysis Many major discrepancies from conceptual to concrete architecture of the Prediction module are the addition of new sub-modules. These include Submodule Output, Util (Data Extraction), Network, Pipeline (Vector Net), Prediction Common, and the Core/Main Files modules. It was expected that the Vector Net would have been stored within the Evaluator; the Core/Main Files \u201cmodule\u201d serves as the main form of reading publish-subscribe messages, as well as writing final Prediction output. Thus, any dependencies to or from these modules were unexpected. There were two dependencies between sub-modules that were seemingly absent in the concrete architecture. The first was the dependency from Predictor to Evaluator; this was displayed as a direct sequential flow in the visualization within the README. However, comments in the Predictor sub-module suggest that this dependency exists, but instead in a publish-subscribe communication format. [GitHub] The other discrepancy was the dependency from Evaluator to Scenario; as with the other dependency, this was expected due to the README, but was missing. As Evaluator largely uses machine learning in its implementation, generating various paths and corresponding probabilities, the scenario may not be as relevant. Inter-module publish-subscribe topics were expected to be read by the Container, as it stores their input data; however, this is absent in the concrete architecture. Instead, these topics are read by the Prediction component\u2019s Core/Main Files. This module also publishes to the ADCTrajectoryContainer and SubmoduleOutput used by the Evaluator and Predictor. The Container, included in the Main Files, processes the received data from the main Prediction component file via ContainerSubmoduleProcess , rather than receiving it itself. Finally, various unanticipated direct dependencies from the sub-modules to other modules may be found. All four original modules depend on the Common module; the Evaluator and Predictor are Cyber RT components. The Container directly includes the Map, by including the hdmap_common.h file for its obstacles and obstacle clusters. Use Cases Use Case 1: Lane Following Figure 10: Sequence diagram for the lane following use case, in accordance with the concrete architecture. In this first use case of lane following, the vehicle stays within a lane while following another car at a safe distance. The diagram in Figure 10 highlights the flow of publish-subscribe channel data. First, the Perception module reads subscribed Drivers messages, which it processes; using the LocalizationEstimate , as well as more sensor data, it determines the perceived obstacles and traffic light status, if applicable. Using published Stories , LocalizationEstimate , PerceptionObstacles , and the ADCTrajectory of the previous cycle, the Prediction module predicts trajectories for the obstacles. The Planning module then plans a trajectory using the PredictionObstacles , TrafficLightDetection , Stories , LocalizationEstimate , MapMsg , RoutingResponse , and Chassis ; it publishes the trajectory to the ADCTrajectory channel. This is used by the Control module, in addition to the Chassis and LocalizationEstimate , to create control commands. The Canbus then reads the ControlCommand to send them to the hardware. Use Case 2: Unprotected Left Turn Figure 11: Sequence diagram for the Unprotected Left Turn use case, centered upon the Planning component. Use Case 2 is the Unprotected Left Turn scenario. In this scenario, the vehicle is to turn left at an intersection with a traffic light; \u201cunprotected\u201d refers to how the traffic light is not using specific turn lights (i.e., left-only). Figure 11 presents a sequence diagram for this use case, which was created after a study of the Planning component code. After the Planning component reads messages from Localization, Storytelling, Prediction, Routing, Canbus, Map, Perception, and itself, it runs various planners once to plan trajectories. These planners use a Scenario Manager, creating the scenario as well as its current stage (Approach if not yet at the intersection, Creep to move forward and survey, and Intersection Cruise to move through). Tasks are found in a Task Factory, including deciding on the speed and path. Once this is complete, the stage, and then scenario, is finished; the Planners generate the trajectory using trajectory generators, and the optimal trajectory is written to the ADCTrajectory topic. [GitHub] Lessons Learned Certain unexpected things complicated the architecture derivation process. Firstly, Understand is unable to detect protobuf dependencies, which means some module dependencies are obscured since they occur in code generated from the protobuf files. Second, the Apollo developers do not write very descriptive commit messages, and most pull requests that were looked at as being relevant to our investigation had no description. Apollo, being a large system, has various modules that are regularly updated over time, and the documentation is not necessarily updated with it; in addition, it may be simplified to the true state of the system for readability purposes or complexity. Glossary HMI: Human Machine Interface LiDAR: Light Detection and Ranging Conti radar: A radar sensor from Continental Engineering. Specifically, Apollo uses the Continental ARS-408-21 Radar package. PnC: Planning and Control CAN: Controller Area Network. A host-less messaging bus protocol primarily used with microcontrollers in automotive contexts. References ApolloAuto. \u201cApolloAuto/apollo: An open autonomous driving platform.\u201d GitHub. Last accessed March 21, 2022. Retrieved from https://github.com/ApolloAuto/apollo. ApolloAuto. \u201cPlanning README at 5.5.0.\u201d GitHub (2020). Retrieved from https://github.com/ApolloAuto/apollo/blob/r5.5.0/modules/planning/README.md. Behere, Sagar, and Martin T\u00f6rngren. \u201cA functional reference architecture for autonomous driving.\u201d KTH The Royal Institute of Technology, Brinellv\u00e4gen 83, Stockholm SE-10044, Sweden (2015): 143. Retrieved from https://www.sciencedirect.com/science/article/abs/pii/S0950584915002177. OBEIA. \u201cThe Conceptual Architecture of Apollo.\u201d February 20, 2022. Retrieved from https://obeia.github.io/assignment1/.","title":"Concrete Architecture"},{"location":"assignment2/#the-concrete-architecture-of-apollo","text":"Click here to access this report as a PDF. (Requires Queen's University login.) Click here to access the accompanying presentation slides. (Requires Queen's University login.)","title":"The Concrete Architecture of Apollo"},{"location":"assignment2/#abstract","text":"As an open-source autonomous driving platform, Apollo understandably is a complex system. Having developed greatly over the years, its architecture has changed over time; thus, its concrete architecture may vary from the conceptual architecture derived from its documentation. To derive the concrete architecture, the Understand 5.1 tool, GitHub repository, and a publish-subscribe communication visualization diagram were utilized to determine dependencies between modules. This process confirmed the publish-subscribe, process-control, and client-server architectural styles determined in the conceptual architecture, but also added three new modules\u2014Drivers, Common, and Task Manager\u2014as well as updated the Map module; various discrepancies were found in the Reflexion Analysis process, including direct code dependencies. The Prediction submodule was also studied in this process, revealing that this module utilizes a combination of the object-oriented and publish-subscribe styles in its predicting of obstacle trajectories, with four core sub-modules: Container, Scenario, Evaluator and Predictor.","title":"Abstract"},{"location":"assignment2/#introduction","text":"Apollo is an open-source platform dedicated to the development and testing of autonomously driving vehicles. As a system that values security and safety while maintaining good performance, Apollo\u2019s developers have created a complex system that largely uses the publish-subscribe style. The system contains a variety of subsystems that provide its functionality while satisfying its requirements, including a Perception module to determine obstacles and details, a Prediction module to predict how the surrounding world and obstacles may change, a Planning module that plans the vehicle\u2019s trajectory, and a Control module that transforms the trajectory into commands for the vehicle to deploy. A conceptual architecture was created by studying a reference architecture [Behere and T\u00f6rngren] as well as utilizing Apollo\u2019s documentation. Although the conceptual architecture may describe the system of Apollo to a degree, there are always limitations to what may be extracted via a reference architecture or system documentation. It may deviate from the reference architecture; the documentation may be a work in progress for the system\u2019s current state, and/or omit minor dependencies. Thus, to fully understand Apollo, one must study its code to determine its concrete architecture. To derive the concrete architectures of both Apollo as a whole and our chosen subsystem, Prediction, we used the Understand tool at version 5.1, as well as a graph visualization of the publish-subscribe communication within the system, and in-depth investigation of the source code. Dependencies found within these visualizations were compared to our conceptual architecture, and discrepancies were added or removed as necessary. These discrepancies were studied in further detail to understand them in various ways, including their purpose and timing. Studying Apollo\u2019s source code reveals three additional modules: Drivers, Task Manager and Common, as well as a module, Map, which contains a component of our conceptual architecture, HD Map, as a sub-component. In addition, although publish-subscribe remains largely what the system is built on, Apollo utilizes direct dependencies in its functionality, particularly to the Map module as well as a Common module, and various calls to include files from different components that help in other components\u2019 function.","title":"Introduction"},{"location":"assignment2/#derivation-process","text":"Figures 1 and 2 visualize the conceptual architecture that was derived from Apollo documentation and the reference architecture. Figure 1 highlights the dependency relations between various modules, while Figure 2 emphasizes the architectural style that Apollo is largely built upon: the publish-subscribe style, where modules publish and subscribe to topics of interest as their main form of communication with one another. Figure 1: Dependency relations of the Apollo architecture, as determined in the conceptual architecture retrieval process. (Corrected to match conceptual architecture report text.) Figure 2: Communication flow within the Apollo conceptual architecture. The conceptual architecture retrieved from various Apollo- and autonomous driving-related sources is an essential aspect of determining and understanding the concrete architecture used by the system. The process of deriving this conceptual architecture, as well as its details, may be found in our previous report. [OBEIA]","title":"Derivation Process"},{"location":"assignment2/#understand-publish-subscribe-and-reflection","text":"One way to derive the concrete architecture of a system is by studying its source code, taking note of when modules and files within them reference other modules, suggesting a dependency. One method of doing so is via the Understand program. Using a file for this program provided by our instructor, we applied Understand 5.1\u2019s dependency diagram tool; this process produces a visual of the dependencies of the system and allows one to view their specifics. However, due to the publish-subscribe style relying upon a central bus, many dependencies are obscured. To mediate this, our instructor provided another diagram, shown in Figure 3, representing the communication between modules in this style. Using these diagrams, we regularly considered our conceptual architecture, adding and removing dependencies as necessary; in considering these dependencies within Understand, we removed test files that did not affect the system itself. When reviewing discrepancies, we also discerned their purpose, timing, and attribution, if applicable, provided in Reflexion Analysis. In our study of the source code, three new modules or sub-components were found: a common module, a task manager, and drivers. Further, rather than HD Map, there is a \u201cMap\u201d module containing the HD Map as a sub-component. These modules are described in further detail with other subsystems of Apollo, within the Concrete Architecture section. The dependency diagrams and publish-subscribe visualization highlight many different dependencies through the system, notably various dependencies that do not occur within the publish-subscribe communication flow. Some dependencies recorded in our conceptual architecture were missing, whereas many unanticipated dependencies were found. Figure 3: Publish-subscribe communication visualization within Apollo.","title":"Understand, Publish-Subscribe and Reflection"},{"location":"assignment2/#concrete-architecture","text":"Figures 4 and 5 present the concrete architecture of Apollo\u2019s software system as code dependencies, Figure 6 presents the architecture as messaging dependencies between modules. The architecture and interactions are described further in the following sub-sections. Figure 4: Apollo system inter-module code dependencies, according to Understand 5.1. Figure 5: Simplified view of Apollo inter-module dependencies. Figure 6: Publish-subscribe communication of the concrete Apollo architecture.","title":"Concrete Architecture"},{"location":"assignment2/#modules-and-subsystems","text":"","title":"Modules and Subsystems"},{"location":"assignment2/#cyber-rt","text":"Apollo\u2019s architecture is built around a custom runtime framework called Cyber RT . Cyber RT has many responsibilities as both a runtime component and a base library for other system modules. At runtime, Cyber manages module loading and most of the inter- and even intra-module communication, through facilities for either publish-subscribe messaging or client-server interaction. Cyber RT also provides code dependencies, including runtime base classes, and utilities for file operations, logging, timing, concurrency, and asynchrony. The publish-subscribe functionality is done through a \u201cchannel\u201d abstraction over multiple transport types, allowing it to be suited for various deployment scenarios. The cyber::Reader class template allows construction of subscribers to a channel and to receive messages on it, either declaring a callback function to trigger when a message is received or allowing messages to be cached for later observation. In many cases, the callback function is simply to store the message so a reference to the latest one is available for use. Publishing to a channel is handled by specializations of the cyber::Writer class template, which can write a single message type to a single channel. On the wire, exchanged messages are byte streams in the protocol buffer (protobuf) encoding format. Each module includes a collection of .proto files which define the messages it sends. Code is generated from the .proto files at build time, which is used by the publishing module for message serialization, and by the subscribing module(s) for deserialization. The Apollo runtime modules are made up of one or more Cyber RT \u201ccomponents\u201d. There are two component base classes that a module can inherit from: cyber::Component (and its various partial specializations) and cyber::TimerComponent . Components inheriting from cyber::Component can declare zero to four message types to listen for and have their main processing logic automatically triggered when a message is received on those channels. Components inheriting from cyber::TimerComponent are instead triggered on certain time intervals. Either type of component can declare additional Reader s, and as many Writer s as required. All components must be registered with Cyber RT to operate. The fundamental nature of Cyber RT means that all other operating subsystems of Apollo depend on it.","title":"Cyber RT"},{"location":"assignment2/#common","text":"While not a running module that provides specific functionality to the system, the Common module contains useful code that other modules may rely on. The contents include global constants (in the form of gflags ) for topic names, vehicle configuration and data, access to system-wide parameters through a key-value database, latency recording and monitor logging, operation statuses, protocol buffer definitions that see use across the entire system, various math and parsing utilities, and a class that models the overall vehicle state, among others. [GitHub] As it is not a runtime module, Common does not exist as a Cyber RT component. Other than Cyber RT, every analyzed Apollo subsystem relies on Common.","title":"Common"},{"location":"assignment2/#drivers","text":"The Drivers module contains code for interfacing with the various hardware components of the Apollo vehicle platform. It contains CAN client code, used both for reading from typical chassis sensors and controlling the vehicle. Additionally, it contains interfaces for the more advanced sensing equipment required for autonomous vehicle operation, including cameras, microphones, LiDAR, radar, and GNSS. These sensors are bridged into the rest of the system by Cyber RT components that write their readings to channels for other modules to read. Some Drivers components are subscribed to messages from the Localization and Canbus modules, relying on them for operational information.","title":"Drivers"},{"location":"assignment2/#guardian","text":"Guardian acts as Apollo\u2019s emergency response system, implemented as a Cyber RT TimerComponent . All messages from Control to Canbus pass through Guardian, which decides whether to block them based on vehicle and system status it receives from Canbus and Monitor. In the event of a system error, Control commands will be blocked, and Guardian will instead direct Canbus to bring the vehicle to a stop.","title":"Guardian"},{"location":"assignment2/#monitor","text":"Monitor is a cyber::TimerComponent that regularly checks the status of the hardware and software of the system, using various mechanisms including OS-level process checks, and status messages on most Cyber RT channels. It reports results on the SystemStatus channel and is also able to directly update Dreamview.","title":"Monitor"},{"location":"assignment2/#dreamview","text":"Apollo\u2019s HMI module, Dreamview , includes a JavaScript frontend that allows users to visualize the data produced by other subsystems, and an on-board backend. Dreamview reads messages from all other modules and produces a three-dimensional representation of the vehicle including the current location and planned path and displays the status of the system components and hardware. Additionally, Dreamview contains a map service that other modules rely on, and an interface to allow certain HMI actions to be carried out.","title":"Dreamview"},{"location":"assignment2/#perception","text":"The Perception subsystem takes input from physical sensors mounted on a vehicle, including cameras, LiDAR sensors, and radar, over channels from the Drivers module. This subsystem outputs decisions on the state of nearby traffic lights and a list of objects which are labelled with their type, distance from the vehicle, and velocity. [GitHub] The module is quite complex and includes ten different Cyber RT components.","title":"Perception"},{"location":"assignment2/#prediction","text":"The Prediction subsystem predicts the future movements of objects identified by the perception module, implemented as a cyber::Component that is triggered by the publishing of PerceptionObstacles messages. [GitHub] This module is described in more detail in the Subsystem: Prediction section of this report. In addition to Perception, the module reads from Storytelling, Map, and Localization subsystem channels.","title":"Prediction"},{"location":"assignment2/#planning","text":"The Planning subsystem aims to plan the exact route of the vehicle. It first plans short term goals such as staying in a lane, then plans the future trajectory of the vehicle. The Planning module may request a new routing computation if unable to follow the original route. [GitHub] Planning is subscribed to seven channels throughout the system; it is directly dependent on Dreamview, Routing, Localization, Prediction and Map.","title":"Planning"},{"location":"assignment2/#localization","text":"The Localization module provides localization services to the platform. This module consists of three different Cyber components that each implement a different localization strategy on what sensors are available to the vehicle, the data from which it reads from channels of the Drivers module; providing an estimate of the vehicle's location as output. [GitHub]","title":"Localization"},{"location":"assignment2/#map","text":"The Map module includes the HD Map found within our conceptual architecture, which served as a query engine for the other modules to provide detailed road information. [GitHub] The Map also includes a PnC Map and Relative Map. [GitHub] It is subscribed to Localization, Canbus, and Perception topics, and has code dependencies on Routing and Planning.","title":"Map"},{"location":"assignment2/#routing","text":"The Routing subsystem generates navigation paths, typically from the vehicle\u2019s current location to the passenger\u2019s destination. Another module can request for routing by publishing a RoutingRequest , which triggers the RoutingComponent (a child of cyber::Component ). Routing\u2019s logic additionally makes direct use of Map to produce a RoutingResponse which can be used by other modules, notably Planning. [GitHub]","title":"Routing"},{"location":"assignment2/#canbus","text":"Acting as the interface between the software system and the physical chassis, Canbus works closely with the Control and Guardian modules, subscribing to and actualizing commands from one of them according to a configuration flag. Canbus also reports the chassis status to the rest of the system and relies heavily on code in Drivers in its operation. [GitHub]","title":"Canbus"},{"location":"assignment2/#storytelling","text":"The Storytelling subsystem is a scenario manager intended to coordinate inter-module actions. This module creates \u201cstories\u201d: complex scenarios that may be used by other modules. [GitHub] This sub-system does not subscribe to any module topics but does write to topics of its own; it is dependent directly on the Map module.","title":"Storytelling"},{"location":"assignment2/#control","text":"The Control subsystem employs various algorithms to generate control commands for the steering, brakes, and throttle, depending on the scenario the vehicle is in. Control passes the commands to the Canbus to control the vehicle hardware. [GitHub] It is subscribed to topics from Planning and Canbus; it both subscribes to topics of and directly depends on Localization.","title":"Control"},{"location":"assignment2/#task-manager","text":"The Task Manager contains various routing managers to be employed by the system as required. It writes to a RoutingRequest channel if the routing process needs to be redone. [GitHub] It is subscribed to topics from the Routing and Localization modules and is directly dependent upon Dreamview and Map.","title":"Task Manager"},{"location":"assignment2/#architectural-styles","text":"Recovering Apollo\u2019s concrete architecture confirmed that publish-subscribe served as the primary form of communication between modules; the method of how it is applied was described in detail previously in the Cyber RT subsystem description. The process-control pattern was confirmed in the concrete architecture, with the Control module acting as the controller, while Canbus acts as the process; here, the Control module creates execution plans, which the Canbus reads and actualizes for the hardware, then provides Chassis data (i.e., feedback) to Control. Finally, the client-server style of interaction via Cyber RT was confirmed; the Cyber RT API for Developers discusses the process in detail, in that it implements two-way communication in this fashion where a node sends a request to receive a response. [GitHub] The Routing channels RoutingResponse and RoutingRequest are one such example of this style.","title":"Architectural Styles"},{"location":"assignment2/#reflexion-analysis","text":"Upon comparison between our conceptual publish-subscribe architecture and the concrete one, several discrepancies were identified in inter-module messaging dependencies. Table 1 describes the expected dependencies that were found to be absent in the concrete architecture. Table 2 describes the concrete dependencies that were not expected in the concrete architecture. Table 1: Conceptual dependencies absent in concrete architecture. Listener Module Talker Module Discrepancy Details Control Storytelling The expectation for Control having a dependency on Storytelling came from the Storytelling documentation listing Control as an example of a module that might subscribe to a story. At this time, there is only one story implemented in Storytelling, which does not require Control to be subscribed. Since any module could subscribe to Storytelling as more stories are implemented, this dependency might exist in the future. Routing Map This expected dependency is not necessarily absent, it instead takes a different form than initially expected. It was expected that communication between Routing and Map would be carried out over Cyber\u2019s publish-subscribe or client-server transports. Instead, it appears to be a direct code dependency. Storytelling Localization In 2020, this dependency was recorded in the README file for Storytelling ( 09a4f00 ); however, study of the code at this period of time reveals direct dependencies to Planning and Prediction that have been removed since, but not Localization either through code or messaging. Storytelling Map This expected dependency is not necessarily absent, it instead takes a different form than initially expected. It was expected that communication between Storytelling and Map would be carried out over Cyber\u2019s publish-subscribe or client-server transports. Instead, it appears to be a direct code dependency. Table 2: Dependencies found in concrete architecture not expected by conceptual. Listener Module Talker Module Discrepancy Details Drivers 1 Canbus The gnss::RawStream class of the GnssDriverComponent is subscribed to Chassis messages. On a timer, it extracts speed data from the message and writes a corresponding wheel velocity command to the command stream. Drivers 1 Localization The ContiRadarCanbusComponent is subscribed to LocalizationEstimate messages to extract the vehicle's pose data. Specifically, it uses orientation and linear velocity to calculate a speed and yaw rate, as required by the radar hardware. Guardian Canbus Guardian is subscribed to Chassis messages from Canbus so it can check for sonar faults and obstacles in the event of an emergency stop when safety mode is triggered. If either are found, the vehicle is supposed to make a hard emergency stop, otherwise a soft one can be made. However, since a change in June 2018, these flags are ignored pending \u201chardware re-alignment.\u201d ( 97b0b3c ) Guardian Control Guardian listens for ControlCommand messages from Control. When the system is not in safety mode, the ControlCommand s are wrapped in a GuardianCommand and published for Canbus to receive. When safety mode is enabled, the commands are blocked from reaching Canbus. Our assumption had been that the safety mode control logic existed in Canbus, which listened for commands from Control and a safety mode state from Guardian and considering both, rather than the commands passing through Guardian. Localization Drivers 1 The Localization module relies on sensor data from Drivers in the form of GnssBestPose , PointCloud , CorrectedImu , and InsStat messages. Map Canbus Chassis messages from Canbus are listened for by the RelativeMap submodule of the Map component. In part of creating the relative map, it uses Chassis and LocalizationEstimate data to update the vehicle state. Map Localization LocalizationEstimate messages from Localization are listened for by the RelativeMap submodule of the Map component. In part of creating the relative map, it uses Chassis and LocalizationEstimate data to update the vehicle state. Map Perception PerceptionObstacles messages from the Perception module that contain lane marker data are used by the RelativeMap submodule of the Map component to create one or more navigation paths in the relative map. Monitor Canbus Initial analysis during the development of the conceptual architecture concluded that Monitor\u2019s monitoring of other Apollo modules was primarily achieved by channel utilities provided by Cyber RT, and operations at the operating system level such as checking system resource usage and that processes are running. While those are all methods that Monitor employs, it also subscribes to topics of various modules to look out for anomalous activity. Control Dreamview Drivers 1 Localization Map Perception Planning Prediction Perception Drivers 1 The Perception module receives LiDAR and radar data in the form of PointCloud and ContiRadar messages, respectively, from the Drivers module. Planning Canbus Planning listens for Chassis messages containing details of the vehicle state. The chassis data is combined with data from the other subscribed inputs as a LocalView , which \u201ccontains all the necessary data as planning input.\u201d This input is not listed as a data input in the Planning documentation, so it was not considered in the conceptual architecture. Prediction Storytelling Prediction is subscribed to Stories messages from Storytelling, in order to be a part of cross-module coordination when a story scenario occurs. Prediction was not listed in the Storytelling documentation as an example subscriber, but any module could potentially be a story subscriber, depending on which stories have been implemented. The only story implemented so far is CloseToJunction , which requires Prediction. Task Manager 2 Localization The Task Manager listens for LocalizationEstimate messages, which it uses for vehicle positioning data. The vehicle coordinates are used to determine the distance to waypoints in cycle and dead-end routing tasks. Task Manager 2 Routing The Task Manager subscribes to RoutingResponse messages to confirm that routing requests that it has made have succeeded. Drivers had not been included in the conceptual architecture as a module, as such all publish-subscribe interactions involving it appear as a divergence. Task Manager had not been included in the conceptual architecture as a module, as such all publish-subscribe interactions involving it appear as a divergence.","title":"Reflexion Analysis"},{"location":"assignment2/#code-dependencies","text":"Even in Apollo\u2019s publish-subscribe architecture, the modules and subsystems are not fully isolated or independent. One category of such code dependency makes complete sense, which is any dependency on the Common or Cyber modules. As described previously, these modules both provide utilities and runtime functionality, and are meant to be relied on in this way. Another category of inter-module code dependency comes from the use of protocol buffers. Every module that publishes messages includes .proto definitions that are used to generate protobuf serialization code at build time. Subscribing modules that need to deserialize the protobuf messages must rely on this generated code as well, which can be seen as #include s for files ending in .pb.h . This sort of dependency between modules is a requirement of the system, and the benefits of using strict schemas enforced by generated code at the expense of full module isolation far outweigh the benefits of full isolation but requiring either unstructured messages or duplicated message class code. However, one case where this is less expected is in the VehicleStateProvider class of the Common module, which depends on Chassis and LocalizationEstimate protobuf code from Canbus and Localization, respectively, as well as in the accompanying vehicle_state.proto which relies on chasis.proto and pose.proto from the same respective modules. It is unusual for a common module to depend on more specific functional modules, even in this way. Other code dependencies that were found are detailed in Table 3. Table 3: Other inter-module code dependencies. Dependent Module Dependency Module Dependency Details Canbus Drivers The Canbus module depends heavily on the Drivers module, specifically the drivers/canbus/ subdirectory. The drivers/canbus/ directory contains CAN client code, such as the base CanClient class, specific CAN client implementations that inherit from CanClient , and the CanClientFactory that registers the clients. The CAN client code used to be part of the Canbus module but was moved to drivers/ since different sensors using the protocol all share use of it. ( 10fb2bf ) Common Localization Common declares a dependency on the localization_gflags.h file in the implementation of the VehicleStateProvider class. The value of this flag is used to choose how to determine the linear acceleration and angular velocity of the vehicle. It is, however, quite odd to see a \u201ccommon\u201d module depend on a specific subsystem. Control Localization The LonController class in the Control module includes the localization_gflags.h file but does not appear to make use of the flags anywhere. The inclusion dates to Apollo 1.0 and the earliest commit in the codebase, but the flags go unused there and in every revision since. The dependency is unnecessary. Dreamview Map Dreamview\u2019s MapService makes use of both hdmap::PncMap and hdmap::HDMap (via hdmap::HDMapUtil ), querying both map models for routing information and road features such as lanes, speedbumps, signs, etc. Additional use of Map classes is used in simulation functionality. Map Planning The hdmap::PncMap class includes planning_gflags.h from the Planning module since December 2017. ( 4abd4e3 ) The class logic continues to make use of these flags. Map Routing At one time, the hdmap::PncMap class was made dependent on one of the flags from routing_gflags.h . ( 1effd0c ) However, the use of this flag was later modified, then removed entirely. ( b3ce40c ) No other Routing flags are used by this class, making the dependency unnecessary. Monitor Dreamview The MonitorManager class has a dependency on the dreamview::HMIWorker , which is a singleton object, as well as on dreamview_gflags.h . The HMIWorker singleton is used to update configs and monitored modules when the HMI status reports a mode change. Perception Map Perception contains the perception::map::HDMapInput class, which is a thread-safe singleton wrapping HDMap for use by the many subcomponents of Perception, including various sensors that need map data, and for sensor fusion. The wrapper includes hdmap.h , hdmap_common.h , and hdmap_util.h . Perception Prediction The Perception module\u2019s multi-LiDAR fusion engine and evaluator manager make use of classes from the Prediction module. The former using the obstacles and pose containers and the latter relying on the semantic LSTM evaluator. This appears to be a case of specialized code reuse for the evaluator use case and not a runtime module interaction. Planning Dreamview planning::OpenSpaceRoiDecider declares a dependency on dreamview::MapService , however it is unclear why. It does not appear to be used. It is possible that the dependency being unused, or the location of its use, is lost in the size of the commit it was introduced in. ( 6db2a1b ) Planning Map The Planning module makes significant use of elements of all three submodules of the Map system, relying on the HD Map, PnC Map, and relative map for road and environment details in navigation planning. Planning Prediction AutotuningMLPModel in Planning extends prediction::network::NetModel , which is a base class for implementing machine learning network models. This is a case of code reuse not module interaction at runtime, but the base class could be considered for extraction into a common library. Planning Routing The planning::ReferenceLineProvider class declares a dependency on routing_gflags.h from the Routing module, since the class logic relied on one of the flags. ( b3ce40c ) The method where the flag was used was later made unreachable, ( c488562 ) and the dead code was removed some time later. ( c0331f9 ) However, the dependency was not removed, despite now being unnecessary. Prediction Map The Prediction module makes use of HD Map as part of its prediction map and semantic map. The primary interaction appears to be positioning and predicting the movement of obstacles relative to lanes, with lane details coming from Map. Routing Map 1 The routing::Routing class declares a dependency on hdmap_util.h from the Map module. It uses a utility from there to get the routing map file to construct a Navigator , and another to receive a pointer to the HDMap object, which it uses to query lanes and parking spaces. Storytelling Map 1 The storytelling::CloseToJunctionTeller class makes use of the hdmap::HDMapUtil class querying details of the surroundings when approaching an intersection. Task Manager Dreamview task_manager::CycleRoutingManager uses a dependency on dreamview::MapService to construct lane waypoints when getting new routing at the beginning/end of a cycle. Task Manager Map Task Manager\u2019s DeadEndRoutingManager and ParkingRoutingManager declare several dependencies on HD Map classes but make no use of them. Like the earlier Planning/Dreamview dependency this was introduced in a very large, squashed commit and it seems likely that the unnecessary dependencies went unnoticed. ( 6db2a1b ) This dependency is notable since in the initial conceptual architecture analysis it was assumed that the communication was done either by the pub-sub channels or Cyber RT\u2019s client-server mechanism. However, it appears to simply be a code dependency.","title":"Code Dependencies"},{"location":"assignment2/#subsystem-prediction","text":"In studying the architecture of Apollo, we chose to study one of its core subsystems, the Prediction module, in further detail. This entailed deriving its conceptual architecture, and then forming its concrete architecture, applying the reflexion analysis in the process.","title":"Subsystem: Prediction"},{"location":"assignment2/#subcomponents","text":"","title":"Subcomponents"},{"location":"assignment2/#container","text":"The Container stores input data that the Prediction module listens for from subscribed topics; currently, these are Perception obstacles, Planning, and Localization. [GitHub]","title":"Container"},{"location":"assignment2/#scenario","text":"The Scenario sub-module defines scenarios that the ego vehicle may be in; currently these scenarios are cruising , which includes lane keeping and following, and junction , which includes intersections with traffic lights and/or stop signs. [GitHub]","title":"Scenario"},{"location":"assignment2/#evaluator","text":"The Evaluator separately predicts the path and speed of each obstacle and evaluates them by outputting a probability that they occur by using a given model. It uses a variety of possible evaluators, and most apply machine learning to determine these probabilities; the models utilized in these machine learning evaluators include RNN, MLP, CNN-1d and social LSTM. For example, the Semantic LSTM Evaluator, used for \u201ccaution\u201d-level obstacles, generates short-term trajectory points via CNN and LSTM. [GitHub]","title":"Evaluator"},{"location":"assignment2/#predictor","text":"The Predictor generates predicted trajectories. A variety of possible predictors are supported, including empty , for obstacles with no predicted trajectories; single lane , where they move along a single lane in \u201chighway navigation mode;\u201d lane sequence , where they move along the lanes; move sequence , moving along the lanes \u201cfollowing its kinetic pattern;\u201d free movement ; regional movement , moving in a possible region; and junction , moving toward junction exits. An interpolation predictor computes the likelihood of creating posterior prediction results after all evaluators have run, intended for \u201ccaution\u201d-level obstacles. An extrapolation predictor creates an 8 sec trajectory, extending the Semantic LSTM Evaluator. [GitHub]","title":"Predictor"},{"location":"assignment2/#conceptual-architecture","text":"To derive the conceptual architecture of the Prediction module, we studied its documentation. The documentation, found in the module README file, provided details on each core sub-module, as well as a diagram presenting their communication and control flow. Figure 7: Conceptual architecture of the Prediction module.","title":"Conceptual Architecture"},{"location":"assignment2/#concrete-architecture_1","text":"As with the concrete architecture of the full system, we studied the dependency diagram formulated by Understand to derive specific dependencies of the system. This, however, has limitations regarding publish-subscribe communication between Prediction\u2019s sub-modules and other modules in the system, as the provided publish-subscribe visualization does not go into such detail. However, a study of the main sub-modules\u2019 code presents that the Evaluator and Predictor modules have publish-subscribe dependencies to other modules. Figure 8: Concrete architecture for the Prediction module. Figure 9: Publish-subscribe communication focused on the Prediction module.","title":"Concrete Architecture"},{"location":"assignment2/#architectural-styles_1","text":"The visual representation of the subcomponent communication reviewed in the conceptual architecture derivation process led us to conclude that the object-oriented style would fit the architecture. This is as the sub-modules would need to know the identities of one another. The Container identifies and protects specific input data; the other sub-modules may use these specific data, i.e., they need to know which data is which, and from which source it is from. This is supported by direct includes in the code to specific Containers in the concrete architecture. In addition to the object-oriented style, Prediction employs some publish-subscribe communication, both in terms of inter-module and intra-module communication. In particular, the Evaluator and Predictor listen for specific topics, which can be seen in their submodule code.","title":"Architectural Styles"},{"location":"assignment2/#reflexion-analysis_1","text":"Many major discrepancies from conceptual to concrete architecture of the Prediction module are the addition of new sub-modules. These include Submodule Output, Util (Data Extraction), Network, Pipeline (Vector Net), Prediction Common, and the Core/Main Files modules. It was expected that the Vector Net would have been stored within the Evaluator; the Core/Main Files \u201cmodule\u201d serves as the main form of reading publish-subscribe messages, as well as writing final Prediction output. Thus, any dependencies to or from these modules were unexpected. There were two dependencies between sub-modules that were seemingly absent in the concrete architecture. The first was the dependency from Predictor to Evaluator; this was displayed as a direct sequential flow in the visualization within the README. However, comments in the Predictor sub-module suggest that this dependency exists, but instead in a publish-subscribe communication format. [GitHub] The other discrepancy was the dependency from Evaluator to Scenario; as with the other dependency, this was expected due to the README, but was missing. As Evaluator largely uses machine learning in its implementation, generating various paths and corresponding probabilities, the scenario may not be as relevant. Inter-module publish-subscribe topics were expected to be read by the Container, as it stores their input data; however, this is absent in the concrete architecture. Instead, these topics are read by the Prediction component\u2019s Core/Main Files. This module also publishes to the ADCTrajectoryContainer and SubmoduleOutput used by the Evaluator and Predictor. The Container, included in the Main Files, processes the received data from the main Prediction component file via ContainerSubmoduleProcess , rather than receiving it itself. Finally, various unanticipated direct dependencies from the sub-modules to other modules may be found. All four original modules depend on the Common module; the Evaluator and Predictor are Cyber RT components. The Container directly includes the Map, by including the hdmap_common.h file for its obstacles and obstacle clusters.","title":"Reflexion Analysis"},{"location":"assignment2/#use-cases","text":"","title":"Use Cases"},{"location":"assignment2/#use-case-1-lane-following","text":"Figure 10: Sequence diagram for the lane following use case, in accordance with the concrete architecture. In this first use case of lane following, the vehicle stays within a lane while following another car at a safe distance. The diagram in Figure 10 highlights the flow of publish-subscribe channel data. First, the Perception module reads subscribed Drivers messages, which it processes; using the LocalizationEstimate , as well as more sensor data, it determines the perceived obstacles and traffic light status, if applicable. Using published Stories , LocalizationEstimate , PerceptionObstacles , and the ADCTrajectory of the previous cycle, the Prediction module predicts trajectories for the obstacles. The Planning module then plans a trajectory using the PredictionObstacles , TrafficLightDetection , Stories , LocalizationEstimate , MapMsg , RoutingResponse , and Chassis ; it publishes the trajectory to the ADCTrajectory channel. This is used by the Control module, in addition to the Chassis and LocalizationEstimate , to create control commands. The Canbus then reads the ControlCommand to send them to the hardware.","title":"Use Case 1: Lane Following"},{"location":"assignment2/#use-case-2-unprotected-left-turn","text":"Figure 11: Sequence diagram for the Unprotected Left Turn use case, centered upon the Planning component. Use Case 2 is the Unprotected Left Turn scenario. In this scenario, the vehicle is to turn left at an intersection with a traffic light; \u201cunprotected\u201d refers to how the traffic light is not using specific turn lights (i.e., left-only). Figure 11 presents a sequence diagram for this use case, which was created after a study of the Planning component code. After the Planning component reads messages from Localization, Storytelling, Prediction, Routing, Canbus, Map, Perception, and itself, it runs various planners once to plan trajectories. These planners use a Scenario Manager, creating the scenario as well as its current stage (Approach if not yet at the intersection, Creep to move forward and survey, and Intersection Cruise to move through). Tasks are found in a Task Factory, including deciding on the speed and path. Once this is complete, the stage, and then scenario, is finished; the Planners generate the trajectory using trajectory generators, and the optimal trajectory is written to the ADCTrajectory topic. [GitHub]","title":"Use Case 2: Unprotected Left Turn"},{"location":"assignment2/#lessons-learned","text":"Certain unexpected things complicated the architecture derivation process. Firstly, Understand is unable to detect protobuf dependencies, which means some module dependencies are obscured since they occur in code generated from the protobuf files. Second, the Apollo developers do not write very descriptive commit messages, and most pull requests that were looked at as being relevant to our investigation had no description. Apollo, being a large system, has various modules that are regularly updated over time, and the documentation is not necessarily updated with it; in addition, it may be simplified to the true state of the system for readability purposes or complexity.","title":"Lessons Learned"},{"location":"assignment2/#glossary","text":"HMI: Human Machine Interface LiDAR: Light Detection and Ranging Conti radar: A radar sensor from Continental Engineering. Specifically, Apollo uses the Continental ARS-408-21 Radar package. PnC: Planning and Control CAN: Controller Area Network. A host-less messaging bus protocol primarily used with microcontrollers in automotive contexts.","title":"Glossary"},{"location":"assignment2/#references","text":"ApolloAuto. \u201cApolloAuto/apollo: An open autonomous driving platform.\u201d GitHub. Last accessed March 21, 2022. Retrieved from https://github.com/ApolloAuto/apollo. ApolloAuto. \u201cPlanning README at 5.5.0.\u201d GitHub (2020). Retrieved from https://github.com/ApolloAuto/apollo/blob/r5.5.0/modules/planning/README.md. Behere, Sagar, and Martin T\u00f6rngren. \u201cA functional reference architecture for autonomous driving.\u201d KTH The Royal Institute of Technology, Brinellv\u00e4gen 83, Stockholm SE-10044, Sweden (2015): 143. Retrieved from https://www.sciencedirect.com/science/article/abs/pii/S0950584915002177. OBEIA. \u201cThe Conceptual Architecture of Apollo.\u201d February 20, 2022. Retrieved from https://obeia.github.io/assignment1/.","title":"References"}]}